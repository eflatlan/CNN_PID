{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3roW1dtSIHSekXzzURVhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eflatlan/CNN_PID/blob/dev_floatmap/cnn_adjusted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py numpy\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrPLFO_92Cvr",
        "outputId": "0c721aac-0d2b-4386-c53f-077934b12dda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py\n",
        "from helper_functions.py import print_points, plot_maps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "_clF1C9YOo3R",
        "outputId": "9212fc8e-962e-4c33-9a27-0af4e8a25470"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 15:30:20--  https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3906 (3.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.4’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   3.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-23 15:30:20 (60.8 MB/s) - ‘helper_functions.py.4’ saved [3906/3906]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-0ba7f7f42232>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0;36m, in \u001b[0;35m<cell line: 2>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from helper_functions.py import print_points, plot_maps\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/helper_functions.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from __future__ import print_function\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "\n",
        "# to check the impact of resolution in the 2d-map; \n",
        "# print the difference between the filledBins vector versus the map (map is restricted by resolution)\n",
        "def print_points(filled_bins_array = None, map_array = None, mip_position_array = None, resolution = 10):\n",
        "\n",
        "    length = map_array.shape[0]\n",
        "    distances_bins_list = []\n",
        "    distances_map_list = []\n",
        "\n",
        "    print(f\"filled_bins_array shape = {filled_bins_array.shape}\")\n",
        "    print(f\"map_array shape = {map_array.shape}\")\n",
        "    print(f\"mip_position_array shape = {mip_position_array.shape}\")\n",
        "\n",
        "\n",
        "    for i in range (1, length):\n",
        "\n",
        "        filled_bins = np.array(filled_bins_array[i])\n",
        "        map = np.array(map_array[i, :,:])\n",
        "        mip_pos = np.array(mip_position_array[i, :])\n",
        "\n",
        "        #print(f\"filled_bins shape = {filled_bins.shape}\")\n",
        "        #print(f\"map shape = {map.shape}\")\n",
        "        #print(f\"mip_pos shape = {mip_pos.shape}\")\n",
        "\n",
        "        _mip_position = []\n",
        "        #_mip_position.append(mip_position_array[])\n",
        "        distances2 = []\n",
        "\n",
        "        distances_bins = [norm(np.array(pos) - mip_pos) for pos in filled_bins]\n",
        "\n",
        "        distances_map = []\n",
        "        for y in range(map.shape[0]):\n",
        "            for x in range(map.shape[1]):\n",
        "                if map[y, x] == 1:\n",
        "                    point = (x, y)\n",
        "                    distance = np.linalg.norm(np.array(point) - mip_pos*resolution)\n",
        "                    distances_map.append(distance)\n",
        "        \n",
        "        \n",
        "        \n",
        "        distances_bins_list.append(distances_bins)\n",
        "        distances_map_list.append(distances_map)\n",
        "\n",
        "\n",
        "    # Print the distances for each element in map_data_list\n",
        "    print(f\"Element {i+1} distances:\")\n",
        "    for j, (distances_bins, distances_map) in enumerate(zip(distances_bins_list, distances_map_list)):\n",
        "        print(f\"  Point {j+1}: Distance bins: {distances_bins}\\n, Distance map: {distances_map}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_maps(filled_bins_array=None, map_array=None, mip_position_array=None, X_momentum=None, X_refractive_index=None, X_ckov=None, percentage_to_plot=5, resolution = 10):\n",
        "  \"\"\"\n",
        "  Args : filled_bins_array : array that holds the vectors of filled pads \n",
        "         map_array : 2d  map with a determined resolution (the points in the filled_bins_array element, just restricted by the resolution)\n",
        "         mip_position_array : array of the MIP {x, y} positions\n",
        "\n",
        "         TODO : add mass_category and actual mass?\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  #percentage_to_plot = 0.05 / 10\n",
        "\n",
        "  # Calculate the starting index of the samples to plot\n",
        "  num_samples = map_array.shape[0]\n",
        "  start_index = -num_samples\n",
        "\n",
        "  # Create a subplot with the number of rows based on the number of samples\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the samples and plot each map with information\n",
        "  for i, ax in enumerate(axes):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = map_array[start_index + i, :, :]\n",
        "      #mass_category = particle_vector[start_index + i].mass_category\n",
        "      ckov = X_ckov[start_index + i]\n",
        "      mip_position = mip_position_array[start_index + i]\n",
        "      momentum = X_momentum[start_index + i]\n",
        "      refractive_index = X_refractive_index[start_index + i]\n",
        "\n",
        "      # Plot the map\n",
        "      ax.imshow(map_data, cmap='gray')\n",
        "\n",
        "      # Add a red dot at the MIP position\n",
        "      ax.plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "\n",
        "      # Set the title with the information\n",
        "      #ax.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "      ax.set_title(f\"CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "\n",
        "      ax.axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y9ZOOuC_Dhay"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_random_element(X_train_map):\n",
        "    index = random.randint(0, len(X_train_map) - 1)  # Pick a random index\n",
        "    element = X_train_map[index, :, :, 0]  # Retrieve the element\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(element, cmap='viridis', origin='lower')\n",
        "    plt.title(f\"Random Element from X_train_map (Index {index})\")\n",
        "    plt.colorbar(label='Intensity')\n",
        "    plt.xlabel('X Axis')\n",
        "    plt.ylabel('Y Axis')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "FmXOGRP_UQZM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot5(X_test_map, particle_vector):\n",
        "\n",
        "  # Plotting random maps with information\n",
        "\n",
        "  # Select 5 random indices from the test data\n",
        "  random_indices = np.random.choice(range(X_test_map.shape[0]), size=5, replace=False)\n",
        "\n",
        "  # Create a subplot with 5 rows and 1 column\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the random indices and plot each map with information\n",
        "  for i, index in enumerate(random_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :, 0]\n",
        "      mass_category = particle_vector[index].mass_category\n",
        "      ckov = particle_vector[index].ckov\n",
        "      mip_position = particle_vector[index].mip_position\n",
        "      momentum = particle_vector[index].momentum\n",
        "      \n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "      \n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "      \n",
        "      # Set the title with the information    a\n",
        "      #x.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position:.4f}, Momentum: {momentum:.4f}\")\n",
        "      mip_pos = f\"{mip_position:.4f}\"\n",
        "      axes[i].set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_pos}, Momentum: {momentum}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PlFS0yz2Feuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lr_scheduler(num_epochs = 10):\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "  div = num_epochs/4\n",
        "  print(\"div =\", div)\n",
        "  print(\"1e-4 * 10**(epoch/div) = \", 1e-4 * 10**(num_epochs/div))\n",
        "  lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/div)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "  return lr_scheduler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_lr(num_epochs = 10, history = None):\n",
        "  div = num_epochs/4\n",
        "  lrs = 1e-4 * (10 ** (np.arange(num_epochs)/div))\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "  plt.xlabel(\"Learning Rate\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "\n",
        "  plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "pcY6LVGpxZQI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def plot_worst_(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "def plot_worst_(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, resolution):\n",
        "  y_pred = model.predict([X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position])\n",
        "  print(\"Shape of y_pred: \", y_pred.shape)\n",
        "  # 1. Predict labels on validation data\n",
        "#plot_worst(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "\n",
        "  # 2. Calculate the difference between predicted and actual labels\n",
        "  losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "  # Sort the indices of the losses from highest to lowest\n",
        "  sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "  # Get the indices of the worst performing 10%\n",
        "  worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "  # Create figure and axes\n",
        "  num_plots = len(worst_10_percent_indices)\n",
        "  #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "  fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "  # Define mass categories\n",
        "  mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "  # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "  for i, index in enumerate(worst_10_percent_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :]\n",
        "      actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "      print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "      predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "      ckov = X_test_ckov[index]\n",
        "      mip_position = X_test_mip_position[index]\n",
        "      momentum = X_test_momentum[index]\n",
        "      refractive_index = X_test_refractive_index[index]\n",
        "      \n",
        "      mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "      \n",
        "      # Check if the value is NaN (invalid Cherenkov angle)\n",
        "      if np.isnan(mass_actual):\n",
        "          mass_actual = \"Invalid\"\n",
        "\n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "\n",
        "      # Set the title with the information\n",
        "      axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      #\n",
        "      axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "      #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "VRoviFHFMvUa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resolution = 4\n",
        "\n",
        "print_vals = False\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, concatenate, BatchNormalization, MaxPooling2D, Dropout, LeakyReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "class Constants:\n",
        "    PION_MASS = 0.1396\n",
        "    KAON_MASS = 0.4937\n",
        "    PROTON_MASS = 0.938\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "@staticmethod\n",
        "def calculate_mass(momentum, refractiveIndex, ckov):\n",
        "    \"\"\" args : momentum, refractiveIndex, ckov\n",
        "        returns : mass\n",
        "    \"\"\"\n",
        "    mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "    return mass\n",
        "\n",
        "\n",
        "class ParticleDataUtils:\n",
        "  \n",
        "    class ParticleInfo:\n",
        "        def __init__(self, momentum, mass, refractiveIndex, ckov, filledBins, mip_position):\n",
        "\n",
        "            self.momentum = momentum\n",
        "            self.mass = mass\n",
        "            self.refractiveIndex = refractiveIndex\n",
        "            self.ckov = ckov\n",
        "            self.filledBins = filledBins\n",
        "            self.mip_position = mip_position\n",
        "            self.mass_category = self.infer_mass_category_from_ckov(momentum, refractiveIndex, ckov)  # Infer mass category based on mass\n",
        "            self.distances_to_mip = self.calculate_distances_to_mip()  # Calculate distances\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category_from_ckov(momentum, refractiveIndex, ckov):\n",
        "            mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "            \n",
        "            mass_category = \"unknown\"\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-4:\n",
        "                mass_category = \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-4:\n",
        "                mass_category = \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-4:\n",
        "                mass_category = \"proton\"\n",
        "            if print_vals:\n",
        "              print(f\"\\ninfer_mass_category_from_ckov :  momentum = {momentum}|  mass_calc = {mass} |  mass_category={mass_category} | refractiveIndex = {refractiveIndex} | ckov = {ckov}\")\n",
        "            return mass_category\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category(mass):\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-6:\n",
        "                return \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-6:\n",
        "                return \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-6:\n",
        "                return \"proton\"\n",
        "            else:\n",
        "                return \"unknown\"\n",
        "\n",
        "        def __str__(self):\n",
        "            if print_vals:\n",
        "              return (f\"ParticleInfo(momentum={self.momentum} | mass={self.mass} |  mass_category={self.mass_category} | \"\n",
        "                      f\"refractiveIndex={self.refractiveIndex} | ckov={self.ckov} | num_filled_bins={len(self.filledBins)}, \"\n",
        "                      f\"mip_position={self.mip_position})\")\n",
        "\n",
        "        def calculate_distances_to_mip(self):\n",
        "            \"\"\"Calculate Euclidean distances from all filled bins to MIP position\"\"\"\n",
        "            distances = [norm(np.array(pos) - self.mip_position) for pos in self.filledBins]\n",
        "            return distances\n",
        "\n",
        "\n",
        "    def __init__(self, filename = \"default_filename.h5\", percentage_to_read = 100):\n",
        "        self.filename = filename\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.particle_vector = self.load_data(filename)\n",
        "        self.particle_info = self.process_data(self.particle_vector, self.percentage_to_read)\n",
        "        self.num_particles = len(self.particle_info)\n",
        "        self.momentum_scaler, self.momentum_stats = self.create_scaler(\"momentum\")\n",
        "        self.refractive_index_scaler, self.refractive_index_stats = self.create_scaler(\"refractiveIndex\")\n",
        "        self.ckov_scaler, self.ckov_stats = self.create_scaler(\"ckov\")\n",
        "        self.distances_scaler, self.distances_stats = self.create_scaler(\"distances\")\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        drive_path = '/content/drive/MyDrive/Colab Notebooks/CERN_ML/CNN_PID/'  # Update the path to your Google Drive folder\n",
        "        file_path = os.path.join(drive_path, filename)\n",
        "        particle_vector = []\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            #file.visititems(print_hdf5_items)\n",
        "            for i, group_name in enumerate(file):\n",
        "                group = file[group_name]\n",
        "\n",
        "                # Read scalar values\n",
        "                momentum = group.attrs['Momentum']\n",
        "                mass = group.attrs['Mass']\n",
        "                refractiveIndex = group.attrs['RefractiveIndex']\n",
        "                ckov = group.attrs['Ckov']\n",
        "                mip_position = group['MipPos']\n",
        "                mip_position = mip_position[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                mip_position = mip_position.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                # Read filledBins\n",
        "                filled_bins_dataset = group['FilledBins']\n",
        "                filled_bins_data = filled_bins_dataset[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                filled_bins = filled_bins_data.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                particle_info = ParticleDataUtils.ParticleInfo(\n",
        "                    momentum, mass, refractiveIndex, ckov, filledBins=filled_bins, mip_position=mip_position)\n",
        "                if print_vals == True:\n",
        "                  print(particle_info)  # This will use the __str__() method of ParticleInfo\n",
        "\n",
        "                particle_vector.append(particle_info)\n",
        "\n",
        "        return particle_vector\n",
        "\n",
        "    def process_data(self, particle_vector, percentage):\n",
        "\n",
        "        # Calculate the number of particles based on the percentage\n",
        "        num_particles = int(len(particle_vector) * (percentage / 100.0))\n",
        "\n",
        "        # Slice the particle_vector to the desired percentage\n",
        "        particle_vector = particle_vector[:num_particles]\n",
        "        return particle_vector\n",
        "\n",
        "\n",
        "    def create_scaler(self, feature):\n",
        "        if feature == \"momentum\":\n",
        "            values = np.array([info.momentum for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"refractiveIndex\":\n",
        "            values = np.array([info.refractiveIndex for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"ckov\":\n",
        "            values = np.array([info.ckov for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"distances\":\n",
        "            distances = []\n",
        "            for info in self.particle_info:\n",
        "                distances.extend(info.distances_to_mip)\n",
        "            values = np.array(distances).reshape(-1, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid feature: {feature}\")\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaled_values = scaler.fit_transform(values)\n",
        "        stats = {\n",
        "            \"mean\": scaler.mean_[0],\n",
        "            \"std\": scaler.scale_[0]\n",
        "        }\n",
        "        return scaler, stats\n",
        "\n",
        "\n",
        "\n",
        "# create a map, the resolution is the \"inverse\" \n",
        "def create_map(filledBins=None, resolution=4):\n",
        "    map_shape = (int(144 * resolution), int(160 * resolution))\n",
        "    map_data = np.zeros(map_shape)\n",
        "    \n",
        "    if filledBins is not None:\n",
        "        for bins in filledBins:\n",
        "            x, y = bins\n",
        "            x_index = int(x * resolution)\n",
        "            y_index = int(y * resolution)\n",
        "            map_data[y_index, x_index] = 1\n",
        "\n",
        "    return map_data\n",
        "\n",
        "class MassClassifier:\n",
        "    def __init__(self, percentage_to_read = 10, resolution = 4):\n",
        "        self.model = None\n",
        "        self.utils = None\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.resolution = resolution\n",
        "\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        self.utils = ParticleDataUtils(filename, percentage_to_read = self.percentage_to_read) # specify percentage of particles to read..\n",
        "        print(f\"Number of particles: {self.utils.num_particles}\")\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        particle_info = self.utils.particle_info\n",
        "\n",
        "\n",
        "        # Prepare the inputs\n",
        "        \n",
        "        # create a map with resolution to be chosen, iterate over teh filledBins vector\n",
        "        X_map = np.array([create_map(filledBins = info.filledBins, resolution = self.resolution) for info in particle_info])\n",
        "        filled_bins_array = np.array([info.filledBins for info in particle_info], dtype=object)\n",
        "\n",
        "        filled_bins_array = np.array([info.filledBins for info in particle_info], dtype=object)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        X_momentum = np.array([info.momentum for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_refractive_index = np.array([info.refractiveIndex for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_ckov = np.array([info.ckov for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_mip_position = np.array([info.mip_position for info in particle_info])\n",
        "\n",
        "        # check the impact of resolution:\n",
        "        #print_points(filled_bins_array = filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, resolution = resolution)\n",
        "\n",
        "        # plot the points and the MIP\n",
        "        #plot_maps(filled_bins_array =filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, X_momentum = X_momentum, X_refractive_index= X_refractive_index, X_ckov = X_ckov, percentage_to_plot=5, resolution = resolution)\n",
        "\n",
        "\n",
        "        # Normalize the inputs NB commented out scaling !!!\n",
        "        #X_momentum = self.utils.momentum_scaler.transform(X_momentum.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_refractive_index = self.utils.refractive_index_scaler.transform(X_refractive_index.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_ckov = self.utils.ckov_scaler.transform(X_ckov.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "\n",
        "        #X_mip_position[0,:] = self.utils.distances_scaler.transform(X_mip_position[0,:])\n",
        "        #X_mip_position[1,:] = self.utils.distances_scaler.transform(X_mip_position[1,:])\n",
        "\n",
        "\n",
        "\n",
        "        # Prepare the outputs\n",
        "        y = np.array([info.mass_category for info in particle_info])\n",
        "\n",
        "        # Convert the outputs to one-hot encoded vectors\n",
        "        lb = LabelBinarizer()\n",
        "        y = lb.fit_transform(y)\n",
        "\n",
        "        # Split the data into train and test sets\n",
        "        X_train_map, X_test_map, X_train_momentum, X_test_momentum, X_train_refractive_index, X_test_refractive_index, \\\n",
        "            X_train_ckov, X_test_ckov, X_train_mip_position, X_test_mip_position, y_train, y_test = \\\n",
        "            train_test_split(X_map, X_momentum, X_refractive_index, X_ckov, X_mip_position, y, test_size=0.2, random_state=42)\n",
        "        #X_train = [X_train_map, X_train_momentum, X_train_refractive_index, X_train_ckov, X_train_mip_position]\n",
        "        #X_test = [X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position]\n",
        "\n",
        "        X_train = {\"X_train_map\": X_train_map, \"X_train_momentum\": X_train_momentum, \"X_train_refractive_index\": X_train_refractive_index, \"X_train_ckov\": X_train_ckov, \"X_train_mip_position\": X_train_mip_position}\n",
        "        X_test = {\"X_test_map\": X_test_map, \"X_test_momentum\": X_test_momentum, \"X_test_refractive_index\": X_test_refractive_index, \"X_test_ckov\": X_test_ckov, \"X_test_mip_position\": X_test_mip_position}\n",
        "\n",
        "        return (X_train, X_test, y_train, y_test)\n",
        "\n",
        "    def build_model(self, map_shape=(None, 2, 1)):\n",
        "        momentum_shape = (1,)\n",
        "        refractive_index_shape = (1,)\n",
        "        mip_position_shape = (2,)\n",
        "\n",
        "        # Grid search parameters\n",
        "        # Grid search parameters\n",
        "        filter_sizes = [5]  # Filter sizes to test\n",
        "        num_filters = [32]#[16, 32]  # Number of filters to test\n",
        "        strides = [(2, 2)]#[(1, 1), (2, 2)]  # Strides to test\n",
        "        pool_sizes = [(2, 2)]  # Max pooling sizes to test\n",
        "        fc1_units = [64]#, 128]  # Number of units in fc1 to test\n",
        "        fc2_units = [16]#, 32]  # Number of units in fc2 to test\n",
        "\n",
        "        best_accuracy = 0\n",
        "        best_model = None\n",
        "\n",
        "        for filter_size in filter_sizes:\n",
        "            for num_filter in num_filters:\n",
        "                for stride in strides:\n",
        "                    for pool_size in pool_sizes:\n",
        "                        for fc1_unit in fc1_units:\n",
        "                            for fc2_unit in fc2_units:\n",
        "                              # Create a new model configuration\n",
        "                              map_input = Input(shape=map_shape, name=\"map_input\")\n",
        "                              momentum_input = Input(shape=momentum_shape, name=\"momentum_input\")\n",
        "                              refractive_index_input = Input(shape=refractive_index_shape, name=\"refractive_index_input\")\n",
        "                              mip_position_input = Input(shape=mip_position_shape, name=\"mip_position_input\")\n",
        "\n",
        "                              conv1 = Conv2D(num_filter, (filter_size * self.resolution, filter_size * self.resolution),\n",
        "                                            strides=(1,1), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.005),\n",
        "                                             bias_regularizer=regularizers.l2(0.01))(map_input)\n",
        "                              conv1 = BatchNormalization()(conv1)\n",
        "                              conv1 = LeakyReLU()(conv1)\n",
        "                              conv1 = MaxPooling2D((2,2))(conv1)\n",
        "                              conv1 = Dropout(0.15)(conv1)\n",
        "\n",
        "                              conv2 = Conv2D(num_filter * 2, ((filter_size+4) * self.resolution, (filter_size+4) * self.resolution),\n",
        "                                            strides=stride, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.005),\n",
        "                                            bias_regularizer=regularizers.l2(0.01))(conv1)\n",
        "                              conv2 = BatchNormalization()(conv2)\n",
        "                              conv2 = LeakyReLU()(conv2)\n",
        "                              conv2 = MaxPooling2D((3,3))(conv2)\n",
        "                              conv2 = Dropout(0.15)(conv2)\n",
        "\n",
        "                              flat_map = Flatten()(conv2)\n",
        "                              concat = concatenate([flat_map, momentum_input, refractive_index_input, mip_position_input])\n",
        "\n",
        "                              fc1 = Dense(fc1_unit, kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), bias_regularizer=regularizers.l2(0.01))(concat)\n",
        "                              fc1 = BatchNormalization()(fc1)\n",
        "                              fc1 = LeakyReLU()(fc1)\n",
        "                              fc1 = Dropout(0.2)(fc1)\n",
        "\n",
        "                              fc2 = Dense(fc2_unit, kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005),\n",
        "                                          bias_regularizer=regularizers.l2(0.01))(fc1)\n",
        "                              fc2 = BatchNormalization()(fc2)\n",
        "                              fc2 = LeakyReLU()(fc2)\n",
        "                              fc2 = Dropout(0.2)(fc2)\n",
        "\n",
        "                              output = Dense(3, activation='softmax')(fc2) # NB LEGG MERKE TIL AT DENNE ER ENDRET FRA FC2\n",
        "\n",
        "                              model = Model(inputs=[map_input, momentum_input, refractive_index_input, mip_position_input],\n",
        "                                            outputs=output)\n",
        "\n",
        "                              model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), # NB changed from 0.0002\n",
        "                                            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "                              X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "                              \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                              # Train the model\n",
        "                              history = model.fit(\n",
        "                                  x=[X_train[\"X_train_map\"], X_train[\"X_train_momentum\"], X_train[\"X_train_refractive_index\"],\n",
        "                                    X_train[\"X_train_mip_position\"]],\n",
        "                                  y=y_train,\n",
        "                                  validation_data=(\n",
        "                                      [X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                      X_test[\"X_test_mip_position\"]],\n",
        "                                      y_test\n",
        "                                  ),\n",
        "                                  batch_size=32,\n",
        "                                  epochs=20,\n",
        "                                  verbose=1\n",
        "                              )\n",
        "\n",
        "                              # plotting the worst cases?:\n",
        "                              #y_pred_test = model.predict([X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_mip_position\"]])\n",
        "                              #plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "                              print(\"Shape of y_test: \", y_test.shape)\n",
        "                              print(\"Shape of X_test_map: \", X_test[\"X_test_map\"].shape)\n",
        "                              print(\"Shape of X_test_momentum: \", X_test[\"X_test_momentum\"].shape)\n",
        "                              print(\"Shape of X_test_refractive_index: \", X_test[\"X_test_refractive_index\"].shape)\n",
        "                              print(\"Shape of X_test_ckov: \", X_test[\"X_test_ckov\"].shape)\n",
        "                              print(\"Shape of X_test_mip_position: \", X_test[\"X_test_mip_position\"].shape)\n",
        "                              #print(\"Shape of y_pred_test: \", y_pred_test.shape)\n",
        "                              try: # NB! commented out this line\n",
        "                                #plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "                                plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], self.resolution)\n",
        "                              except Exception as e:\n",
        "                                print(f\"skip plot_worst_ due to error: {e}\")\n",
        "                              self.plot_training_history(history)\n",
        "\n",
        "                              # Evaluate the model\n",
        "                              _, accuracy = model.evaluate(\n",
        "                                  x=[X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                    X_test[\"X_test_mip_position\"]],\n",
        "                                  y=y_test,\n",
        "                                  verbose=1\n",
        "                              )\n",
        "\n",
        "                              print(f\"Model Accuracy: {accuracy:.4f} (Filter Size: {filter_size}, Num Filters: {num_filter}, \"\n",
        "                                    f\"Stride: {stride}, Pool Size: {pool_size})\")\n",
        "\n",
        "                              # Check if the current model configuration is better\n",
        "                              if accuracy > best_accuracy:\n",
        "                                  best_accuracy = accuracy\n",
        "                                  best_model = model\n",
        "\n",
        "        # Set the best model as the final model\n",
        "        self.model = best_model\n",
        "\n",
        "\n",
        "    def train_model(self, X_train, X_test, y_train, y_test):\n",
        "        # Compile the model\n",
        "\n",
        "        X_train_map = X_train[\"X_train_map\"]\n",
        "        X_train_momentum = X_train[\"X_train_momentum\"]\n",
        "        X_train_refractive_index = X_train[\"X_train_refractive_index\"]\n",
        "        X_train_ckov = X_train[\"X_train_ckov\"]\n",
        "        X_train_mip_position = X_train[\"X_train_mip_position\"]\n",
        "\n",
        "        X_test_map = X_test[\"X_test_map\"]\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        # Print fields in the first vector of X_train\n",
        "        print(\"Fields in the first vector of X_train:\")\n",
        "        print(\"X_train_map shape:\", X_train_map.shape)\n",
        "        print(\"X_train_momentum shape:\", X_train_momentum.shape)\n",
        "        print(\"X_train_refractive_index shape:\", X_train_refractive_index.shape)\n",
        "        print(\"X_train_ckov shape:\", X_train_ckov.shape)\n",
        "        print(\"X_train_mip_position shape:\", X_train_mip_position.shape)\n",
        "\n",
        "        # Print the first element of y_train\n",
        "        print(\"First element of y_train:\", y_train[0])\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            x=[X_train_map, X_train_momentum, X_train_refractive_index, X_train_mip_position], # [X_train_map, X_train_momentum, X_train_refractive_index, X_train_ckov, X_train_mip_position]\n",
        "            y=y_train,\n",
        "            validation_data=(\n",
        "                [X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "                y_test\n",
        "            ),\n",
        "            batch_size=16,\n",
        "            epochs=10,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        X_test_map = X_test[\"X_test_map\"]\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        loss, accuracy = self.model.evaluate(\n",
        "            x=[X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "            y=y_test,\n",
        "            verbose=0\n",
        "        )\n",
        "        print(f\"Test Loss: {loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "        plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, filename):\n",
        "        self.load_data(filename)\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        X_train_map = X_train[\"X_train_map\"]\n",
        "        X_train_map = X_train_map.reshape(X_train_map.shape[0], X_train_map.shape[1], X_train_map.shape[2], 1)\n",
        "        self.build_model(map_shape = X_train_map.shape[1:])\n",
        "        history = self.train_model(X_train, X_test, y_train, y_test)\n",
        "        self.evaluate_model(X_test, y_test)\n",
        "        self.plot_training_history(history)\n",
        "\n",
        "\n",
        "\n",
        "    def plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "      # 1. Predict labels on validation data\n",
        "\n",
        "      # 2. Calculate the difference between predicted and actual labels\n",
        "      losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "      # Sort the indices of the losses from highest to lowest\n",
        "      sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "      # Get the indices of the worst performing 10%\n",
        "      worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "      # Create figure and axes\n",
        "      num_plots = len(worst_10_percent_indices)\n",
        "      #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "      fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "      # Define mass categories\n",
        "      mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "      # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "      for i, index in enumerate(worst_10_percent_indices):\n",
        "          # Get the map and corresponding information\n",
        "          map_data = X_test_map[index, :, :]\n",
        "          actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "          print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "          predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "          ckov = X_test_ckov[index]\n",
        "          mip_position = X_test_mip_position[index]\n",
        "          momentum = X_test_momentum[index]\n",
        "          refractive_index = X_test_refractive_index[index]\n",
        "          \n",
        "          mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "          \n",
        "          # Check if the value is NaN (invalid Cherenkov angle)\n",
        "          if np.isnan(mass_actual):\n",
        "              mass_actual = \"Invalid\"\n",
        "\n",
        "          # Plot the map\n",
        "          axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "          # Add a red dot at the MIP position\n",
        "          axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "\n",
        "          # Set the title with the information\n",
        "          axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          #\n",
        "          axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "          #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          axes[i].axis('off')\n",
        "\n",
        "          print(\"\\n\")\n",
        "          print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      # Adjust the spacing between subplots\n",
        "      plt.tight_layout()\n",
        "\n",
        "      # Show the plot\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "# Usage example\n",
        "classifier = MassClassifier(percentage_to_read = 10, resolution = 4) # pass percentage of dataset to read \n",
        "classifier.train(\"ParticleInfo.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjrxNzz0LMqU",
        "outputId": "179a4a25-182a-4179-a58f-6b255951abd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of particles: 977\n",
            "Epoch 1/20\n",
            "25/25 [==============================] - 96s 4s/step - loss: 113.0354 - accuracy: 0.3470 - val_loss: 59.2687 - val_accuracy: 0.3776\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 90s 4s/step - loss: 43.5980 - accuracy: 0.3303 - val_loss: 34.8865 - val_accuracy: 0.3112\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 90s 4s/step - loss: 33.3745 - accuracy: 0.3508 - val_loss: 32.2069 - val_accuracy: 0.3265\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 99s 4s/step - loss: 30.7847 - accuracy: 0.3457 - val_loss: 30.3311 - val_accuracy: 0.3163\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 90s 4s/step - loss: 29.5178 - accuracy: 0.3265 - val_loss: 28.2365 - val_accuracy: 0.3520\n",
            "Epoch 6/20\n",
            "12/25 [=============>................] - ETA: 41s - loss: 28.1237 - accuracy: 0.3203"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoauWOieMnWE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training accuracy and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DxlPsrmTHFXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "\n",
        "\n",
        "y_train_pred = model.predict([X_train_map, X_train_momentum, X_train_refractive_index, X_train_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "#cm = confusion_matrix(y_train, y_train_pred_classes)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_train, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_train_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Training Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bLBU0quO4IYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_val_pred = model.predict([X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_val_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Validation Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v-ED5GaZ5265"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}