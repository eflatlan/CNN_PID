{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNqHWuR5lXaxzoaYFN7QIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eflatlan/CNN_PID/blob/dev_floatmap/Dense_radius_notCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py numpy\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "mrPLFO_92Cvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py\n",
        "#from helper_functions.py import print_points, plot_mapsm"
      ],
      "metadata": {
        "id": "_clF1C9YOo3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calc_dist2mip(maps = None,  mip_positions = None, resolution = 10):\n",
        "#        X_dist2mip = calc_dist2mip(maps = X_map, mip_positions = X_mip_position, resolution = resolution)\n",
        "\n",
        "    length = maps.shape[0]\n",
        "    distances_map_list = []\n",
        "\n",
        "\n",
        "\n",
        "    #i = 0\n",
        "    for i in range (length):\n",
        "\n",
        "        map = np.array(maps[i, :,:])\n",
        "        mip_pos = np.array(mip_positions[i, :]).copy()\n",
        "\n",
        "        #print(f\"filled_bins shape = {filled_bins.shape}\")\n",
        "        #print(f\"map shape = {map.shape}\")\n",
        "        #print(f\"mip_pos shape = {mip_pos.shape}\")\n",
        "\n",
        "        _mip_position = []\n",
        "\n",
        "\n",
        "        # start vectorization\n",
        "        # Assuming your map is a numpy array\n",
        "        indices = np.where(map == 1)\n",
        "\n",
        "        # Now indices[0] contains the y-indices and indices[1] contains the x-indices\n",
        "        points = np.stack(indices, axis=-1)  # Shape is [num_points, 2]\n",
        "        mip_pos = np.array([mip_pos[1], mip_pos[0]]) * resolution\n",
        "        distances = np.linalg.norm(points - mip_pos, axis=-1)\n",
        "        distances = distances[distances < 20*resolution]  # Filter out large distances\n",
        "                                                          # later do this instead by imposing the masshypothesis\n",
        "        # end vectorization\n",
        "\n",
        "        #distances_map = []\n",
        "        #for y in range(map.shape[0]):\n",
        "        #    for x in range(map.shape[1]):\n",
        "        #        if map[y, x] == 1:\n",
        "        #            point = (x, y)\n",
        "        #            distance = np.linalg.norm(np.array(point) - mip_pos*resolution)\n",
        "        #            if distance < 80*resolution: # dont add if distance is unreasonably large\n",
        "        #              distances_map.append(distance)\n",
        "      \n",
        "      \n",
        "        distances_map_list.append(distances)\n",
        "       # print(f\"calc_dist2mip : distances : {distances}\")\n",
        "       # print(f\"calc_dist2mip : mip_pos * resolution : {mip_pos}\")\n",
        "       # print(f\"calc_dist2mip : points : {points}\")\n",
        "\n",
        "    # TODO: NB this should be removed, if i dont add it distances_map_list is one elem shorter than the other dataframes\n",
        "      \n",
        "    #distances_map_list.append(temp)\n",
        "\n",
        "\n",
        "    print(f\"maps shape = {maps.shape}\")\n",
        "    print(f\"mip_position_array shape = {mip_positions.shape}\")\n",
        "    print(f\"distances_map_list shape = {np.array(distances_map_list, dtype=object).shape}\")\n",
        "\n",
        "    return distances_map_list"
      ],
      "metadata": {
        "id": "I1_O0VK5wqfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class Constants:\n",
        "    def __init__(self):\n",
        "        self.defaultPhotonEnergy = 6.75\n",
        "        self.CH4GapWidth = 8.0\n",
        "        self.RadiatorWidth = 1.0\n",
        "        self.QuartzWindowWidth = 0.5\n",
        "        self.EmissionLength = self.RadiatorWidth / 2.0\n",
        "\n",
        "class Masses:\n",
        "    def __init__(self):\n",
        "        self.mass_Pion = 0.1396\n",
        "        self.mass_Kaon = 0.4937\n",
        "        self.mass_Proton = 0.938\n",
        "\n",
        "\n",
        "# Create constants and masses objects outside of CkovCalculator\n",
        "constants = Constants()\n",
        "masses = Masses()\n",
        "\n",
        "class CkovCalculator:\n",
        "    #def __init__(self):\n",
        "        #self.constants = constants\n",
        "        #self.masses = masses\n",
        "    def GetFreonIndexOfRefraction(self, photonEnergy):\n",
        "        x = photonEnergy\n",
        "        k = 1.177 + (0.0172) * x\n",
        "        return k\n",
        "\n",
        "    def GetQuartzIndexOfRefraction(self, x):\n",
        "        k = math.sqrt(1 + 46.411 / (113.763556 - x) + 228.71 / (328.51563 - x))\n",
        "        return k\n",
        "\n",
        "    def getRadiusFromCkov(self, ckovAngle):\n",
        "        refIndexFreon = self.GetFreonIndexOfRefraction(constants.defaultPhotonEnergy)\n",
        "        refIndexQuartz = self.GetQuartzIndexOfRefraction(constants.defaultPhotonEnergy)\n",
        "        refIndexCH4 = 1.0\n",
        "\n",
        "        sin_ckov = math.sin(ckovAngle)\n",
        "        sin_qz = sin_ckov * (refIndexFreon / refIndexQuartz)\n",
        "        sin_theta0 = sin_qz * (refIndexQuartz / refIndexCH4)\n",
        "\n",
        "        R_ckov = sin_ckov * (constants.RadiatorWidth - constants.EmissionLength)\n",
        "        R_qz = sin_qz * constants.QuartzWindowWidth\n",
        "        R_0 = sin_theta0 * constants.CH4GapWidth\n",
        "\n",
        "        R = R_ckov + R_qz + R_0\n",
        "        return R\n",
        "\n",
        "    def calcCkovFromMass(self, p, n):\n",
        "        p_sq = p * p\n",
        "        cos_ckov_denom = p * n\n",
        "\n",
        "        radiuses = {}\n",
        "\n",
        "        for particle, mass in masses.__dict__.items():\n",
        "            # Skip non-mass attributes\n",
        "            if not particle.startswith(\"mass\"):\n",
        "                continue\n",
        "\n",
        "            mass_value = getattr(masses, particle)\n",
        "\n",
        "            # sanity check\n",
        "            if p_sq + mass_value * mass_value < 0:\n",
        "                radiuses[particle] = 0.0\n",
        "                continue\n",
        "\n",
        "            cos_ckov = math.sqrt(p_sq + mass_value * mass_value) / cos_ckov_denom\n",
        "\n",
        "            # sanity check\n",
        "            if cos_ckov > 1 or cos_ckov < -1:\n",
        "                radiuses[particle] = 0.0\n",
        "                continue\n",
        "\n",
        "            ckovAngle = math.acos(cos_ckov)\n",
        "            radius = self.getRadiusFromCkov(ckovAngle)\n",
        "            radiuses[particle] = radius\n",
        "            #print(f\"{particle} mass_value = {mass_value} Radius: {radius} ckov = {ckovAngle} momentum = {p} refindex = {n}\")\n",
        "\n",
        "        return radiuses\n",
        "\n",
        "\n",
        "# Usage within a loop\n",
        "for i in range(10):\n",
        "    calculator = CkovCalculator()\n",
        "    momentum = 1.5\n",
        "    refractive_index = 1.289\n",
        "    results = calculator.calcCkovFromMass(momentum, refractive_index)\n",
        "    \n",
        "    radiuses = results\n",
        "\n",
        "    radiuses = []\n",
        "\n",
        "    for particle, radius in results.items():\n",
        "        #print(f\"{particle} Radius: {radius}\")\n",
        "        radiuses.append(radius)\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "axtgHsp2colX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "\n",
        "# to check the impact of resolution in the 2d-map; \n",
        "# print the difference between the filledBins vector versus the map (map is restricted by resolution)\n",
        "def print_points(filled_bins_array = None, map_array = None, mip_position_array = None, resolution = 10):\n",
        "\n",
        "    length = map_array.shape[0]\n",
        "    distances_bins_list = []\n",
        "    distances_map_list = []\n",
        "\n",
        "    print(f\"filled_bins_array shape = {filled_bins_array.shape}\")\n",
        "    print(f\"map_array shape = {map_array.shape}\")\n",
        "    print(f\"mip_position_array shape = {mip_position_array.shape}\")\n",
        "\n",
        "\n",
        "    for i in range (1, length):\n",
        "\n",
        "        filled_bins = np.array(filled_bins_array[i])\n",
        "        map = np.array(map_array[i, :,:])\n",
        "        mip_pos = np.array(mip_position_array[i, :])\n",
        "\n",
        "        #print(f\"filled_bins shape = {filled_bins.shape}\")\n",
        "        #print(f\"map shape = {map.shape}\")\n",
        "        #print(f\"mip_pos shape = {mip_pos.shape}\")\n",
        "\n",
        "        _mip_position = []\n",
        "        #_mip_position.append(mip_position_array[])\n",
        "        distances2 = []\n",
        "\n",
        "        distances_bins = [norm(np.array(pos) - mip_pos) for pos in filled_bins]\n",
        "\n",
        "        distances_map = []\n",
        "        for y in range(map.shape[0]):\n",
        "            for x in range(map.shape[1]):\n",
        "                if map[y, x] == 1:\n",
        "                    point = (x, y)\n",
        "                    distance = np.linalg.norm(np.array(point) - mip_pos*resolution)\n",
        "                    distances_map.append(distance)\n",
        "        \n",
        "        \n",
        "        \n",
        "        distances_bins_list.append(distances_bins)\n",
        "        distances_map_list.append(distances_map)\n",
        "\n",
        "\n",
        "    # Print the distances for each element in map_data_list\n",
        "    print(f\"Element {i+1} distances:\")\n",
        "    for j, (distances_bins, distances_map) in enumerate(zip(distances_bins_list, distances_map_list)):\n",
        "        print(f\"  Point {j+1}: Distance bins: {distances_bins}\\n, Distance map: {distances_map}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_maps(filled_bins_array=None, map_array=None, mip_position_array=None, X_momentum=None, X_refractive_index=None, X_ckov=None, percentage_to_plot=5, resolution = 10):\n",
        "  \"\"\"\n",
        "  Args : filled_bins_array : array that holds the vectors of filled pads \n",
        "         map_array : 2d  map with a determined resolution (the points in the filled_bins_array element, just restricted by the resolution)\n",
        "         mip_position_array : array of the MIP {x, y} positions\n",
        "\n",
        "         TODO : add mass_category and actual mass?\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  #percentage_to_plot = 0.05 / 10\n",
        "\n",
        "  # Calculate the starting index of the samples to plot\n",
        "  num_samples = map_array.shape[0]\n",
        "  start_index = -num_samples\n",
        "\n",
        "  # Create a subplot with the number of rows based on the number of samples\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the samples and plot each map with information\n",
        "  for i, ax in enumerate(axes):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = map_array[start_index + i, :, :]\n",
        "      #mass_category = particle_vector[start_index + i].mass_category\n",
        "      ckov = X_ckov[start_index + i]\n",
        "      mip_position = mip_position_array[start_index + i]\n",
        "      momentum = X_momentum[start_index + i]\n",
        "      refractive_index = X_refractive_index[start_index + i]\n",
        "\n",
        "      # Plot the map\n",
        "      ax.imshow(map_data, cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "      #try :\n",
        "      # Add a red dot at the MIP position\n",
        "      ax.plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "      #Except exception as e : \n",
        "      #  print(\"caught non mip pos \")\n",
        "      # Set the title with the information\n",
        "      #ax.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "      ax.set_title(f\"CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "\n",
        "      ax.axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y9ZOOuC_Dhay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_random_element(X_train_map):\n",
        "    index = random.randint(0, len(X_train_map) - 1)  # Pick a random index\n",
        "    element = X_train_map[index, :, :, 0]  # Retrieve the element\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(element, cmap='viridis', origin='lower')\n",
        "    plt.title(f\"Random Element from X_train_map (Index {index})\")\n",
        "    plt.colorbar(label='Intensity')\n",
        "    plt.xlabel('X Axis')\n",
        "    plt.ylabel('Y Axis')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "FmXOGRP_UQZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot5(X_test_map, particle_vector):\n",
        "\n",
        "  # Plotting random maps with information\n",
        "\n",
        "  # Select 5 random indices from the test data\n",
        "  random_indices = np.random.choice(range(X_test_map.shape[0]), size=5, replace=False)\n",
        "\n",
        "  # Create a subplot with 5 rows and 1 column\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the random indices and plot each map with information\n",
        "  for i, index in enumerate(random_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :, 0]\n",
        "      mass_category = particle_vector[index].mass_category\n",
        "      ckov = particle_vector[index].ckov\n",
        "      mip_position = particle_vector[index].mip_position\n",
        "      momentum = particle_vector[index].momentum\n",
        "      \n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "      \n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "      \n",
        "      # Set the title with the information    a\n",
        "      #x.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position:.4f}, Momentum: {momentum:.4f}\")\n",
        "      mip_pos = f\"{mip_position:.4f}\"\n",
        "      axes[i].set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_pos}, Momentum: {momentum}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PlFS0yz2Feuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lr_scheduler(num_epochs = 10):\n",
        "\n",
        "  start_lr = 0.1\n",
        "  end_lr = 5e-6\n",
        "  exp_decay = -np.log(end_lr/start_lr) / num_epochs # Calculate decay rate based on start and end learning rate\n",
        "\n",
        "  lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: start_lr * np.exp(-exp_decay * epoch)) \n",
        "  return lr_scheduler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_lr(num_epochs = 10, history = None):\n",
        "  div = num_epochs/4\n",
        "  lrs = 1e-4 * (10 ** (np.arange(num_epochs)/div))\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "  plt.xlabel(\"Learning Rate\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "\n",
        "  plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "pcY6LVGpxZQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def plot_worst_(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "def plot_maps(filled_bins_array=None, map_array=None, mip_position_array=None, X_momentum=None, X_refractive_index=None, X_ckov=None, percentage_to_plot=5, resolution = 10):\n",
        "  #  print(\"Shape of y_pred: \", y_pred.shape)\n",
        "  # 1. Predict labels on validation data\n",
        "  #plot_worst(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "\n",
        "  # 2. Calculate the difference between predicted and actual labels\n",
        "  losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "  # Sort the indices of the losses from highest to lowest\n",
        "  sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "  # Get the indices of the worst performing 10%\n",
        "  worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "  # Create figure and axes\n",
        "  num_plots = len(worst_10_percent_indices)\n",
        "  #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "  fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "  # Define mass categories\n",
        "  mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "  # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "  for i, index in enumerate(worst_10_percent_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :]\n",
        "      actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "      print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "      predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "      ckov = X_test_ckov[index]\n",
        "      mip_position = X_test_mip_position[index]\n",
        "      momentum = X_test_momentum[index]\n",
        "      refractive_index = X_test_refractive_index[index]\n",
        "      \n",
        "      mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "      \n",
        "      # Check if the value is NaN (invalid Cherenkov angle)\n",
        "      if np.isnan(mass_actual):\n",
        "          mass_actual = \"Invalid\"\n",
        "\n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "\n",
        "      # Set the title with the information\n",
        "      axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      #\n",
        "      axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "      #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "VRoviFHFMvUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_circular_mask(center, size, mean_radius, std):\n",
        "    H, W = size\n",
        "    Y, X = np.ogrid[:H, :W]\n",
        "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
        "\n",
        "    mask = (dist_from_center >= mean_radius - 2*std) & (dist_from_center <= mean_radius + 2*std)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def extract_segment_around_mip(mip_positions = None, window_sizes = None, maps = None, std = 7):\n",
        "    \"\"\"\n",
        "    Args : mip_positions : array of the MIP-positions, (num_samples, {x, y})\n",
        "           window_sizes : radius of the segments (num_samples, 3) 3 = number of particle classes\n",
        "           maps : the photon hit-maps (num_samples, 144*resolution, 160*resolution)\n",
        "           std : standard deviatons to be applied to the ring-radius \n",
        "           \n",
        "    Returns : the extracted regions for each of the different radiuses (m_pion, m_kaon, m_proton), masked with the map\n",
        "    \"\"\"\n",
        "    \n",
        "    windows = []\n",
        "\n",
        "    for mip_position, window_size, map in zip(mip_positions, window_sizes, maps):\n",
        "        radius = np.mean(window_size)\n",
        "        #std = np.std(window_size)\n",
        "\n",
        "        mask = create_circular_mask(mip_position, map.shape, radius, std)\n",
        "\n",
        "        window = np.where(mask, map, 0)\n",
        "\n",
        "        windows.append(window)\n",
        "\n",
        "    return np.array(windows)\n"
      ],
      "metadata": {
        "id": "OReWmp0Mq9JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resolution = 4\n",
        "\n",
        "print_vals = False\n",
        "from numpy.linalg import norm\n",
        "from tensorflow.keras.backend import expand_dims\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Activation, Input, Conv2D, Lambda, Flatten, Dense, concatenate, BatchNormalization, MaxPooling2D, Dropout, LeakyReLU, Masking\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "class Constants:\n",
        "    PION_MASS = 0.1396\n",
        "    KAON_MASS = 0.4937\n",
        "    PROTON_MASS = 0.938\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "@staticmethod\n",
        "def calculate_mass(momentum, refractiveIndex, ckov):\n",
        "    \"\"\" args : momentum, refractiveIndex, ckov\n",
        "        returns : mass\n",
        "    \"\"\"\n",
        "    mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "    return mass\n",
        "\n",
        "\n",
        "class ParticleDataUtils:\n",
        "  \n",
        "    class ParticleInfo:\n",
        "        def __init__(self, momentum, mass, refractiveIndex, ckov, filledBins, mip_position, radiuses):\n",
        "\n",
        "            self.momentum = momentum\n",
        "            self.mass = mass\n",
        "            self.refractiveIndex = refractiveIndex\n",
        "            self.ckov = ckov\n",
        "            self.filledBins = filledBins\n",
        "            self.mip_position = mip_position\n",
        "            self.mass_category = self.infer_mass_category_from_ckov(momentum, refractiveIndex, ckov)  # Infer mass category based on mass\n",
        "            self.distances_to_mip = self.calculate_distances_to_mip()  # Calculate distances\n",
        "            self.radiuses = radiuses\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category_from_ckov(momentum, refractiveIndex, ckov):\n",
        "            mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "            \n",
        "            mass_category = \"unknown\"\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-4:\n",
        "                mass_category = \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-4:\n",
        "                mass_category = \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-4:\n",
        "                mass_category = \"proton\"\n",
        "            if print_vals:\n",
        "              print(f\"\\ninfer_mass_category_from_ckov :  momentum = {momentum}|  mass_calc = {mass} |  mass_category={mass_category} | refractiveIndex = {refractiveIndex} | ckov = {ckov}\")\n",
        "            return mass_category\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category(mass):\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-6:\n",
        "                return \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-6:\n",
        "                return \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-6:\n",
        "                return \"proton\"\n",
        "            else:\n",
        "                return \"unknown\"\n",
        "\n",
        "        def __str__(self):\n",
        "            if print_vals:\n",
        "              return (f\"ParticleInfo(momentum={self.momentum} | mass={self.mass} |  mass_category={self.mass_category} | \"\n",
        "                      f\"refractiveIndex={self.refractiveIndex} | ckov={self.ckov} | num_filled_bins={len(self.filledBins)}, \"\n",
        "                      f\"mip_position={self.mip_position})\")\n",
        "\n",
        "        def calculate_distances_to_mip(self):\n",
        "            \"\"\"Calculate Euclidean distances from all filled bins to MIP position\"\"\"\n",
        "            filledBins_np = np.array(self.filledBins)\n",
        "            mip_position_np = np.array(self.mip_position)\n",
        "\n",
        "            distances = np.linalg.norm(filledBins_np - mip_position_np, axis=1)\n",
        "            return distances\n",
        "\n",
        "\n",
        "    def __init__(self, filename = \"default_filename.h5\", percentage_to_read = 100):\n",
        "        self.filename = filename\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.particle_vector = self.load_data(filename)\n",
        "        self.particle_info = self.process_data(self.particle_vector, self.percentage_to_read)\n",
        "        self.num_particles = len(self.particle_info)\n",
        "        self.momentum_scaler, self.momentum_stats = self.create_scaler(\"momentum\")\n",
        "        self.refractive_index_scaler, self.refractive_index_stats = self.create_scaler(\"refractiveIndex\")\n",
        "        self.ckov_scaler, self.ckov_stats = self.create_scaler(\"ckov\")\n",
        "        self.distances_scaler, self.distances_stats = self.create_scaler(\"distances\")\n",
        "\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        drive_path = '/content/drive/MyDrive/Colab Notebooks/CERN_ML/CNN_PID/'  # Update the path to your Google Drive folder\n",
        "        file_path = os.path.join(drive_path, filename)\n",
        "        particle_vector = []\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            #file.visititems(print_hdf5_items)\n",
        "            for i, group_name in enumerate(file):\n",
        "                group = file[group_name]\n",
        "\n",
        "                # Read scalar values\n",
        "                momentum = group.attrs['Momentum']\n",
        "                mass = group.attrs['Mass']\n",
        "                refractiveIndex = group.attrs['RefractiveIndex']\n",
        "                ckov = group.attrs['Ckov']\n",
        "                mip_position = group['MipPos']\n",
        "                mip_position = mip_position[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                mip_position = mip_position.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                # Read filledBins\n",
        "                filled_bins_dataset = group['FilledBins']\n",
        "                filled_bins_data = filled_bins_dataset[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                filled_bins = filled_bins_data.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                # get window : \n",
        "                calculator = CkovCalculator()\n",
        "                results = calculator.calcCkovFromMass(momentum, refractive_index)\n",
        "                radiuses = []\n",
        "                for particle, radius in results.items():\n",
        "                    #print(f\"{particle} Radius: {radius}\")\n",
        "                    radiuses.append(radius)\n",
        "\n",
        "                # the biggest radius should then extract a window around the MIP \n",
        "\n",
        "                # Find the particle with the biggest radius\n",
        "                #max_radius_particle = max(radiuses, key=radiuses.get)\n",
        "                #max_radius = radiuses[max_radius_particle]\n",
        "                max_radius = radiuses[2]\n",
        "\n",
        "                # Extract a window around the MIP using the biggest radius\n",
        "                #window_size = int(max_radius * 2)  # Adjust the size as needed      \n",
        "                # NB!!! add resolution here? Or multiply elswhere..\n",
        "\n",
        "                particle_info = ParticleDataUtils.ParticleInfo(\n",
        "                    momentum, mass, refractiveIndex, ckov, filledBins=filled_bins, mip_position=mip_position, radiuses = radiuses)\n",
        "                if print_vals == True:\n",
        "                  print(particle_info)  # This will use the __str__() method of ParticleInfo\n",
        "\n",
        "                particle_vector.append(particle_info)\n",
        "\n",
        "        return particle_vector\n",
        "\n",
        "    def process_data(self, particle_vector, percentage):\n",
        "\n",
        "        # Calculate the number of particles based on the percentage\n",
        "        num_particles = int(len(particle_vector) * (percentage / 100.0))\n",
        "\n",
        "        # Slice the particle_vector to the desired percentage\n",
        "        particle_vector = particle_vector[:num_particles]\n",
        "        return particle_vector\n",
        "\n",
        "\n",
        "    def create_scaler(self, feature):\n",
        "        if feature == \"momentum\":\n",
        "            values = np.array([info.momentum for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"refractiveIndex\":\n",
        "            values = np.array([info.refractiveIndex for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"ckov\":\n",
        "            values = np.array([info.ckov for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"distances\":\n",
        "            distances = []\n",
        "            for info in self.particle_info:\n",
        "                distances.extend(info.distances_to_mip)\n",
        "            values = np.array(distances).reshape(-1, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid feature: {feature}\")\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaled_values = scaler.fit_transform(values)\n",
        "        stats = {\n",
        "            \"mean\": scaler.mean_[0],\n",
        "            \"std\": scaler.scale_[0]\n",
        "        }\n",
        "        return scaler, stats\n",
        "\n",
        "\n",
        "\n",
        "# create a map, the resolution is the \"inverse\" \n",
        "def create_map(filledBins=None, resolution=4):\n",
        "    map_shape = (int(144 * resolution), int(160 * resolution))\n",
        "    map_data = np.zeros(map_shape, dtype=np.int32)\n",
        "   \n",
        "    if filledBins is not None:\n",
        "        filledBins_np = np.array(filledBins)\n",
        "        indices = (filledBins_np * resolution).astype(int)\n",
        "        map_data[indices[:, 1], indices[:, 0]] = 1\n",
        "\n",
        "    return map_data\n",
        "\n",
        "class MassClassifier:\n",
        "    def __init__(self, percentage_to_read = 10, resolution = 4):\n",
        "        self.model = None\n",
        "        self.utils = None\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.resolution = resolution\n",
        "\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        self.utils = ParticleDataUtils(filename, percentage_to_read = self.percentage_to_read) # specify percentage of particles to read..\n",
        "        print(f\"Number of particles: {self.utils.num_particles}\")\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        particle_info = self.utils.particle_info\n",
        "\n",
        "\n",
        "        # Prepare the inputs\n",
        "        \n",
        "        # create a map with resolution to be chosen, iterate over teh filledBins vector\n",
        "        X_map = np.array([create_map(filledBins = info.filledBins, resolution = self.resolution) for info in particle_info])\n",
        "        filled_bins_array = np.array([info.filledBins for info in particle_info], dtype=object)\n",
        "\n",
        "\n",
        "\n",
        "        X_momentum = np.array([info.momentum for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_refractive_index = np.array([info.refractiveIndex for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_ckov = np.array([info.ckov for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_mip_position = np.array([info.mip_position for info in particle_info])\n",
        "\n",
        "        # calculate radiuses (radius of f(m_i) where m_i = [m_pion, m_kaon, m_proton],  and n, p, + later {xRad, yRad, theta, phi} fixed for a given track) \n",
        "        # for mass-hypothesis\n",
        "\n",
        "        #alc_dist2mip(maps = None,  mip_positions = None, resolution = 10):\n",
        "        \n",
        "        try:\n",
        "          plot_maps(filled_bins_array=filled_bins_array, map_array=X_map, mip_position_array=X_mip_position, X_momentum=X_momentum, X_refractive_index=X_refractive_index, X_ckov=X_ckov, percentage_to_plot=5, resolution = self.resolution)\n",
        "        except Exception as e:\n",
        "          print(f\"plot_maps failed due to error : {e}\")\n",
        "        \n",
        "        # change shape to be num_samples, pad_sequences, 3:\n",
        "\n",
        "\n",
        "\n",
        "        X_dist2mip = calc_dist2mip(maps = X_map, mip_positions = X_mip_position, resolution = self.resolution)\n",
        "\n",
        "        print(f\" X_dist2mip shape befoer pad = {np.array(X_dist2mip).shape}\")\n",
        "\n",
        "\n",
        "        X_dist2mip = pad_sequences(X_dist2mip, padding='post')\n",
        "        print(f\" X_dist2mip shape after pad = {np.array(X_dist2mip).shape}\")\n",
        "\n",
        "        # extracting the window around the MIP:\n",
        "\n",
        "        #  extract_segment_around_mip(mip_positions = None, radiuses = None, maps = None, std = 7):\n",
        "        #X_windows = extract_segment_around_mip(mip_positions = X_mip_position, radiuses = X_radiuses, maps = X_map, std = 7)\n",
        "        \n",
        "        # this adds wrong? denne dimensionen er en for stor allerede?\n",
        "        #X_windows = np.expand_dims(X_windows, -1) \n",
        "        #print(f\"X_windows shape = {np.array(X_windows).shape}\")\n",
        "        # X_windows will have various size (X_window_sizes + pad) x (X_window_sizes + pad) \n",
        "\n",
        "\n",
        "        # check the impact of resolution:\n",
        "        #print_points(filled_bins_array = filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, resolution = resolution)\n",
        "\n",
        "        # plot the points and the MIP\n",
        "        #plot_maps(filled_bins_array =filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, X_momentum = X_momentum, X_refractive_index= X_refractive_index, X_ckov = X_ckov, percentage_to_plot=5, resolution = resolution)\n",
        "\n",
        "\n",
        "        # Normalize the inputs NB commented out scaling !!!\n",
        "        #X_momentum = self.utils.momentum_scaler.transform(X_momentum.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_refractive_index = self.utils.refractive_index_scaler.transform(X_refractive_index.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_ckov = self.utils.ckov_scaler.transform(X_ckov.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "\n",
        "        #X_mip_position[0,:] = self.utils.distances_scaler.transform(X_mip_position[0,:])\n",
        "        #X_mip_position[1,:] = self.utils.distances_scaler.transform(X_mip_position[1,:])\n",
        "\n",
        "\n",
        "\n",
        "        # Prepare the outputs\n",
        "        y = np.array([info.mass_category for info in particle_info])\n",
        "\n",
        "        # Convert the outputs to one-hot encoded vectors\n",
        "        lb = LabelBinarizer()\n",
        "        y = lb.fit_transform(y)\n",
        "\n",
        "        # Split the data into train and test sets\n",
        "\n",
        "        X_train_dist2mip, X_test_dist2mip, X_train_map, X_test_map, X_train_momentum, X_test_momentum, X_train_refractive_index, X_test_refractive_index, \\\n",
        "            X_train_ckov, X_test_ckov, X_train_mip_position, X_test_mip_position, y_train, y_test = \\\n",
        "            train_test_split(X_dist2mip, X_map, X_momentum, X_refractive_index, X_ckov, X_mip_position, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        X_train = {\"X_train_map\": X_train_map, \"X_train_momentum\": X_train_momentum, \"X_train_refractive_index\": X_train_refractive_index,\n",
        "                   \"X_train_ckov\": X_train_ckov, \"X_train_mip_position\": X_train_mip_position, \"X_train_dist2mip\": X_train_dist2mip}\n",
        "\n",
        "        X_test = {\"X_test_map\": X_test_map, \"X_test_momentum\": X_test_momentum, \"X_test_refractive_index\": X_test_refractive_index,\n",
        "                  \"X_test_ckov\": X_test_ckov, \"X_test_mip_position\": X_test_mip_position, \"X_test_dist2mip\": X_test_dist2mip}\n",
        "\n",
        "        return (X_train, X_test, y_train, y_test)\n",
        "\n",
        "    def build_model(self, input_sequence_length = None):\n",
        "\n",
        "        #map_shape = (None, None, 1)  # Variable shape for the map input\n",
        "\n",
        "        momentum_shape = (1,)\n",
        "        refractive_index_shape = (1,)\n",
        "        mip_position_shape = (2,)\n",
        "\n",
        "        # Grid search parameters\n",
        "        # Grid search parameters\n",
        "        filter_sizes = [5]  # Filter sizes to test\n",
        "        num_filters = [32]#[16, 32]  # Number of filters to test\n",
        "        strides = [(2, 2)]#[(1, 1), (2, 2)]  # Strides to test\n",
        "        pool_sizes = [(2, 2)]  # Max pooling sizes to test\n",
        "        fc1_units = [64]#, 128]  # Number of units in fc1 to test\n",
        "        fc2_units = [32, 64]#, 32]  # Number of units in fc2 to test\n",
        "\n",
        "        dropouts = [0.2, 0.3, 0.4]\n",
        "        best_accuracy = 0\n",
        "        best_model = None\n",
        "\n",
        "        for dropout in dropouts:\n",
        "            for num_filter in num_filters:\n",
        "                for stride in strides:\n",
        "                    for pool_size in pool_sizes:\n",
        "                        for fc1_unit in fc1_units:\n",
        "                            for fc2_unit in fc2_units:\n",
        "                              # Create a new model configuration\n",
        "\n",
        "                              # X_dist2mip\n",
        "\n",
        "\n",
        "\n",
        "                              #dist2mip_input = Input(shape=dist2mip_shape, name=\"dist2mip_input\")\n",
        "                              momentum_input = Input(shape=momentum_shape, name=\"momentum_input\")\n",
        "                              refractive_index_input = Input(shape=refractive_index_shape, name=\"refractive_index_input\")\n",
        "                              mip_position_input = Input(shape=mip_position_shape, name=\"mip_position_input\")\n",
        "\n",
        "\n",
        "\n",
        "                              # Distance to MIP:\n",
        "                              dist2mip_input = Input(shape=(input_sequence_length,), name=\"dist2mip_input\")\n",
        "\n",
        "                              # to ignore the padded values:\n",
        "                              dist2mip_masked = Masking(mask_value=0.)(dist2mip_input)\n",
        "\n",
        "                              dense_dist2mip_1 = Dense(128, name=\"dense_dist2mip_1\")(dist2mip_masked)\n",
        "                              bn_dist2mip_1 = BatchNormalization(name=\"bn_dist2mip_1\")(dense_dist2mip_1)\n",
        "                              relu_dist2mip_1 = Activation('relu', name=\"relu_dist2mip_1\")(bn_dist2mip_1)\n",
        "                              dropout_dist2mip_1 = Dropout(dropout, name=\"dropout_dist2mip_1\")(relu_dist2mip_1)\n",
        "\n",
        "                              dense_dist2mip_2 = Dense(64, name=\"dense_dist2mip_2\")(dropout_dist2mip_1)\n",
        "                              bn_dist2mip_2 = BatchNormalization(name=\"bn_dist2mip_2\")(dense_dist2mip_2)\n",
        "                              relu_dist2mip_2 = Activation('relu', name=\"relu_dist2mip_2\")(bn_dist2mip_2)\n",
        "                              dropout_dist2mip_2 = Dropout(0.2, name=\"dropout_dist2mip_2\")(relu_dist2mip_2)\n",
        "\n",
        "                              dense_dist2mip_3 = Dense(32, name=\"dense_dist2mip_3\")(dropout_dist2mip_2)\n",
        "                              bn_dist2mip_3 = BatchNormalization(name=\"bn_dist2mip_3\")(dense_dist2mip_3)\n",
        "                              relu_dist2mip_3 = Activation('relu', name=\"relu_dist2mip_3\")(bn_dist2mip_3)\n",
        "                              dropout_dist2mip_3 = Dropout(0.2, name=\"dropout_dist2mip_3\")(relu_dist2mip_3)\n",
        "\n",
        "                              dense_dist2mip_4 = Dense(16, name=\"dense_dist2mip_4\")(dropout_dist2mip_3)\n",
        "                              bn_dist2mip_4 = BatchNormalization(name=\"bn_dist2mip_4\")(dense_dist2mip_4)\n",
        "                              relu_dist2mip_4 = Activation('relu', name=\"relu_dist2mip_4\")(bn_dist2mip_4)\n",
        "                              dropout_dist2mip_4 = Dropout(0.2, name=\"dropout_dist2mip_4\")(relu_dist2mip_4)\n",
        "\n",
        "\n",
        "                              # NB! now skipping the BatchNormalization\n",
        "                              # Refractive index Input\n",
        "                              # Refractive index Input\n",
        "                              dense_ref_index = Dense(fc1_unit, name=\"dense_ref_index\")(refractive_index_input)\n",
        "                              bn_ref_index = BatchNormalization(name=\"bn_ref_index\")(dense_ref_index)\n",
        "                              relu_ref_index = Activation('relu', name=\"relu_ref_index\")(bn_ref_index)\n",
        "                              dropout_ref_index = Dropout(dropout, name=\"dropout_ref_index\")(relu_ref_index)\n",
        "\n",
        "                              dense_ref_index_2 = Dense(fc1_unit/2, name=\"dense_ref_index_2\")(dropout_ref_index)\n",
        "                              bn_ref_index_2 = BatchNormalization(name=\"bn_ref_index_2\")(dense_ref_index_2)\n",
        "                              relu_ref_index_2 = Activation('relu', name=\"relu_ref_index_2\")(bn_ref_index_2)\n",
        "                              dropout_ref_index_2 = Dropout(dropout, name=\"dropout_ref_index_2\")(relu_ref_index_2)\n",
        "\n",
        "\n",
        "                              # Momentum Input\n",
        "                              dense_momentum = Dense(fc1_unit, name=\"dense_momentum\")(momentum_input)\n",
        "                              bn_momentum = BatchNormalization(name=\"bn_momentum\")(dense_momentum)\n",
        "                              relu_momentum = Activation('relu', name=\"relu_momentum\")(bn_momentum)\n",
        "                              dropout_momentum = Dropout(dropout, name=\"dropout_momentum\")(relu_momentum)\n",
        "\n",
        "                              dense_momentum_2 = Dense(fc1_unit/2, name=\"dense_momentum_2\")(dropout_momentum)\n",
        "                              bn_momentum_2 = BatchNormalization(name=\"bn_momentum_2\")(dense_momentum_2)\n",
        "                              relu_momentum_2 = Activation('relu', name=\"relu_momentum_2\")(bn_momentum_2)\n",
        "                              dropout_momentum_2 = Dropout(dropout, name=\"dropout_momentum_2\")(relu_momentum_2)\n",
        "\n",
        "\n",
        "                              # MIP Position Input\n",
        "                              dense_mip_pos = Dense(fc1_unit, name=\"dense_mip_pos\")(mip_position_input)\n",
        "                              bn_mip_pos = BatchNormalization(name=\"bn_mip_pos\")(dense_mip_pos)\n",
        "                              relu_mip_pos = Activation('relu', name=\"relu_mip_pos\")(bn_mip_pos)\n",
        "                              dropout_mip_pos = Dropout(dropout, name=\"dropout_mip_pos\")(relu_mip_pos)\n",
        "\n",
        "                              dense_mip_pos_2 = Dense(fc1_unit/2, name=\"dense_mip_pos_2\")(dropout_mip_pos)\n",
        "                              bn_mip_pos_2 = BatchNormalization(name=\"bn_mip_pos_2\")(dense_mip_pos_2)\n",
        "                              relu_mip_pos_2 = Activation('relu', name=\"relu_mip_pos_2\")(bn_mip_pos_2)\n",
        "                              dropout_mip_pos_2 = Dropout(dropout, name=\"dropout_mip_pos_2\")(relu_mip_pos_2)\n",
        "\n",
        "                              \n",
        "                              epochs = 300\n",
        "                              lr = create_lr_scheduler(num_epochs = epochs)\n",
        "\n",
        "                              # Concatenation\n",
        "                              concat = concatenate([dropout_dist2mip_3, dropout_ref_index_2, dropout_momentum_2, dropout_mip_pos_2])\n",
        "\n",
        "\n",
        "                              dense_concat = Dense(16, name=\"dense_concat\")(concat)\n",
        "                              bn_concat = BatchNormalization(name=\"bn_concat\")(dense_concat)\n",
        "                              relu_concat = Activation('relu', name=\"relu_concat\")(dense_mip_pos)\n",
        "                              dropout_concat = Dropout(dropout, name=\"dropout_concat\")(relu_concat)\n",
        "\n",
        "\n",
        "                              output = Dense(3, activation='softmax')(concat) # NB LEGG MERKE TIL AT DENNE ER ENDRET FRA FC2\n",
        "\n",
        "                              model = Model(inputs=[dist2mip_input, momentum_input, refractive_index_input, mip_position_input],\n",
        "                                            outputs=output)\n",
        "\n",
        "                              #model = Model(inputs=[window_input], outputs=[output])\n",
        "                              model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), # NB changed from 0.0002\n",
        "                                            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "                              X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "\n",
        "                              # Train the model\n",
        "                              history = model.fit(\n",
        "                                  x=[X_train[\"X_train_dist2mip\"], X_train[\"X_train_momentum\"], X_train[\"X_train_refractive_index\"],\n",
        "                                      X_train[\"X_train_mip_position\"]], # x=[X_train_dist2mip, X_train_momentum, X_train_refractive_index, X_train_ckov, X_train_mip_position]\n",
        "                                  y=y_train,\n",
        "                                  validation_data=(\n",
        "                                      [X_test[\"X_test_dist2mip\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                        X_test[\"X_test_mip_position\"]],\n",
        "                                      y_test\n",
        "                                  ),\n",
        "                                  batch_size=32,\n",
        "                                  epochs=epochs,\n",
        "                                  verbose=1,\n",
        "                                  callbacks = [lr]\n",
        "                              )\n",
        "\n",
        "                              # plotting the worst cases?:\n",
        "                              #y_pred_test = model.predict([X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_mip_position\"]])\n",
        "                              #plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "                              print(\"Shape of y_test: \", y_test.shape)\n",
        "                              print(\"Shape of X_test_map: \", X_test[\"X_test_map\"].shape)\n",
        "                             # print(\"Shape of X_test_windows: \", X_test[\"X_test_windows\"].shape)\n",
        "                              print(\"Shape of X_test_momentum: \", X_test[\"X_test_momentum\"].shape)\n",
        "                              print(\"Shape of X_test_refractive_index: \", X_test[\"X_test_refractive_index\"].shape)\n",
        "                              print(\"Shape of X_test_ckov: \", X_test[\"X_test_ckov\"].shape)\n",
        "                              print(\"Shape of X_test_mip_position: \", X_test[\"X_test_mip_position\"].shape)\n",
        "                              #print(\"Shape of y_pred_test: \", y_pred_test.shape)\n",
        "                              try: # NB! commented out this line\n",
        "                                #plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "                                plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], self.resolution)\n",
        "                              except Exception as e:\n",
        "                                print(f\"skip plot_worst_ due to error: {e}\")\n",
        "                              self.plot_training_history(history)\n",
        "\n",
        "                              # Evaluate the model\n",
        "                              _, accuracy = model.evaluate(\n",
        "                                  x=[X_test[\"X_test_dist2mip\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                        X_test[\"X_test_mip_position\"]],\n",
        "                                  y=y_test,\n",
        "                                  verbose=1\n",
        "                              )\n",
        "\n",
        "                              print(f\"Model Accuracy: {accuracy:.4f} (fc1 Size: {fc1_unit}, Num fc2: {fc2_unit}, dropout = {dropout}\")\n",
        "\n",
        "\n",
        "                              # Check if the current model configuration is better\n",
        "                              if accuracy > best_accuracy:\n",
        "                                  best_accuracy = accuracy\n",
        "                                  best_model = model\n",
        "\n",
        "        # Set the best model as the final model\n",
        "        self.model = best_model\n",
        "\n",
        "\n",
        "    def train_model(self, X_train, X_test, y_train, y_test):\n",
        "        # Compile the model\n",
        "\n",
        "\n",
        "        X_train_map = X_train[\"X_train_map\"]\n",
        "        X_train_dist2mip = X_train[\"X_train_dist2mip\"]\n",
        "        X_train_momentum = X_train[\"X_train_momentum\"]\n",
        "        X_train_refractive_index = X_train[\"X_train_refractive_index\"]\n",
        "        X_train_ckov = X_train[\"X_train_ckov\"]\n",
        "        X_train_mip_position = X_train[\"X_train_mip_position\"]\n",
        "\n",
        "        X_test_map = X_test[\"X_test_map\"]\n",
        "        X_test_dist2mip = X_test[\"X_test_dist2mip\"]\n",
        "\n",
        "\n",
        "        # Define the bin edges for each histogram.\n",
        "        bins1 = np.arange(0, self.resolution*10.1, 0.01)\n",
        "        bins2 = np.arange(4, self.resolution*8.1, 0.01)\n",
        "        bins3 = np.arange(0, self.resolution*2.1, 0.01)\n",
        "\n",
        "        # Create a figure with 3 subplots (one row, three columns).\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        \n",
        "        num_zeros = np.sum(X_train_dist2mip == 0)\n",
        "\n",
        "\n",
        "        mask = (X_test_dist2mip >= self.resolution*1) & (X_test_dist2mip <= self.resolution*8)\n",
        "\n",
        "        # Index your array with the mask\n",
        "        selected_values = X_test_dist2mip[mask]\n",
        "        num_elements = int(0.1 * len(selected_values))\n",
        "\n",
        "        # Print the selected values\n",
        "        first_10_percent = selected_values[:num_elements]\n",
        "\n",
        "        # Print these elements\n",
        "        print(selected_values)\n",
        "\n",
        "        print(f'There are {num_zeros} zeros in X_train_dist2mip.')\n",
        "        print(f\"X_train_dist2mip shape = {np.array(X_train_dist2mip).shape}\")\n",
        "\n",
        "        # Plot the first histogram.\n",
        "        axs[0].hist(X_test_dist2mip, bins=bins1, edgecolor='black')\n",
        "        axs[0].set_title('Histogram 1 of X_test_dist2mip')\n",
        "        axs[0].set_xlabel('Values')\n",
        "        axs[0].set_ylabel('Frequency')\n",
        "\n",
        "        # Plot the second histogram.\n",
        "        axs[1].hist(X_test_dist2mip, bins=bins2, edgecolor='black')\n",
        "        axs[1].set_title('Histogram 2 of X_test_dist2mip')\n",
        "        axs[1].set_xlabel('Values')\n",
        "        axs[1].set_ylabel('Frequency')\n",
        " \n",
        "        # Plot the third histogram.\n",
        "        axs[2].hist(X_test_dist2mip, bins=np.arange(0, .01, 0.001), edgecolor='black')\n",
        "        axs[2].set_title('Histogram 3 of X_test_dist2mip')\n",
        "        axs[2].set_xlabel('Values')\n",
        "        axs[2].set_ylabel('Frequency')\n",
        "\n",
        "        # Display the plot.\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        # # Define the bin edges for each histogram.\n",
        "        # bins11 = np.arange(self.resolution*0.5, self.resolution*10.1, 0.1)\n",
        "        # bins22 = np.arange(self.resolution*0.5, self.resolution*2.1, 0.1)\n",
        "        # bins33 = np.arange(self.resolution*0.5, self.resolution*5.1, 0.1)\n",
        "\n",
        "        # # Create histograms without plotting, to identify peaks.\n",
        "        # hist1, edges1 = np.histogram(X_test_dist2mip, bins=bins11)\n",
        "        # hist2, edges2 = np.histogram(X_test_dist2mip, bins=bins22)\n",
        "        # hist3, edges3 = np.histogram(X_test_dist2mip, bins=bins33)\n",
        "\n",
        "        # # Find peaks (you might want to adjust the parameters).\n",
        "        # peaks1, _ = find_peaks(hist1, height=10) # adjust the height as per your requirement\n",
        "        # peaks2, _ = find_peaks(hist2, height=10)\n",
        "        # peaks3, _ = find_peaks(hist3, height=10)\n",
        "\n",
        "        # # Create a figure with 3 subplots (one row, three columns).\n",
        "        # fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        # # Plot the first histogram with peaks.\n",
        "        # axs[0].hist(X_test_dist2mip, bins=bins11, edgecolor='black')\n",
        "        # axs[0].plot(edges1[peaks1], hist1[peaks1], \"ro\") # Peaks marked in red\n",
        "        # axs[0].set_title('Histogram 1 with Peaks')\n",
        "        # axs[0].set_xlabel('Values')\n",
        "        # axs[0].set_ylabel('Frequency')\n",
        "\n",
        "        # # Plot the second histogram with peaks.\n",
        "        # axs[1].hist(X_test_dist2mip, bins=bins22, edgecolor='black')\n",
        "        # axs[1].plot(edges2[peaks2], hist2[peaks2], \"ro\") # Peaks marked in red\n",
        "        # axs[1].set_title('Histogram 2 with Peaks')\n",
        "        # axs[1].set_xlabel('Values')\n",
        "        # axs[1].set_ylabel('Frequency')\n",
        "\n",
        "        # # Plot the third histogram with peaks.\n",
        "        # axs[2].hist(X_test_dist2mip, bins=bins33, edgecolor='black')\n",
        "        # axs[2].plot(edges3[peaks3], hist3[peaks3], \"ro\") # Peaks marked in red\n",
        "        # axs[2].set_title('Histogram 3 with Peaks')\n",
        "        # axs[2].set_xlabel('Values')\n",
        "        # axs[2].set_ylabel('Frequency')\n",
        "\n",
        "        # # Display the plot.\n",
        "        # plt.tight_layout()\n",
        "        # plt.show()\n",
        "\n",
        "        # for i in range(5):\n",
        "        #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        #   temp = X_test_dist2mip[:, i]\n",
        "        #   max_value = np.max(temp)\n",
        "        #   print(f\"max_value = {max_value}\")\n",
        "        #   print(f\"temp shape = {np.array(temp).shape}\")\n",
        "          \n",
        "        #   # Plot the first histogram.\n",
        "        #   axs[0].hist(temp, bins=bins1, edgecolor='black')\n",
        "        #   axs[0].set_title(f'{i} X_test_dist2mip')\n",
        "        #   axs[0].set_xlabel('Values')\n",
        "        #   axs[0].set_ylabel('Frequency')\n",
        "\n",
        "        #   # Plot the second histogram.\n",
        "        #   axs[1].hist(temp, bins=bins2, edgecolor='black')\n",
        "        #   axs[1].set_title(f'{i} X_test_dist2mip')\n",
        "        #   axs[1].set_xlabel('Values')\n",
        "        #   axs[1].set_ylabel('Frequency')\n",
        "\n",
        "        #   # Plot the third histogram.\n",
        "        #   axs[2].hist(temp, bins=bins3, edgecolor='black')\n",
        "        #   axs[2].set_title(f'{i} X_test_dist2mip')\n",
        "        #   axs[2].set_xlabel('Values')\n",
        "        #   axs[2].set_ylabel('Frequency')\n",
        "\n",
        "        #   # Display the plot.\n",
        "        #   plt.tight_layout()\n",
        "        #   plt.show()\n",
        "\n",
        "        # for i in range(5):\n",
        "        #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        #   temp = X_test_dist2mip[i, :]\n",
        "        #   max_value = np.max(temp)\n",
        "        #   print(f\"max_value = {max_value}\")\n",
        "        #   print(f\"temp shape = {np.array(temp).shape}\")\n",
        "\n",
        "        #   # Plot the first histogram.\n",
        "        #   axs[0].hist(temp, bins=bins1, edgecolor='black')\n",
        "        #   axs[0].set_title(f'{i} a X_test_dist2mip')\n",
        "        #   axs[0].set_xlabel('a Values')\n",
        "        #   axs[0].set_ylabel('Frequency')\n",
        "\n",
        "        #   # Plot the second histogram.\n",
        "        #   axs[1].hist(temp, bins=bins2, edgecolor='black')\n",
        "        #   axs[1].set_title(f'{i} a X_test_dist2mip')\n",
        "        #   axs[1].set_xlabel('a Values')\n",
        "        #   axs[1].set_ylabel('a Frequency')\n",
        "\n",
        "        #   # Plot the third histogram.\n",
        "        #   axs[2].hist(temp, bins=bins3*10, edgecolor='black')\n",
        "        #   axs[2].set_title(f'{i} a X_test_dist2mip')\n",
        "        #   axs[2].set_xlabel('a Values')\n",
        "        #   axs[2].set_ylabel('a Frequency')\n",
        "\n",
        "        #   # Display the plot.\n",
        "        #   plt.tight_layout()\n",
        "        #   plt.show()\n",
        "\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        \n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        # Print fields in the first vector of X_train\n",
        "        print(\"Fields in the first vector of X_train:\")\n",
        "        print(\"X_train_map shape:\", X_train_map.shape)\n",
        "        print(\"X_train_momentum shape:\", X_train_momentum.shape)\n",
        "        print(\"X_train_refractive_index shape:\", X_train_refractive_index.shape)\n",
        "        print(\"X_train_ckov shape:\", X_train_ckov.shape)\n",
        "        print(\"X_train_mip_position shape:\", X_train_mip_position.shape)\n",
        "\n",
        "        # Print the first element of y_train\n",
        "        print(\"First element of y_train:\", y_train[0])\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            x=[X_train_dist2mip, X_train_momentum, X_train_refractive_index, X_train_mip_position],\n",
        "            y=y_train,\n",
        "            validation_data=(\n",
        "                [X_test_dist2mip,  X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "                y_test\n",
        "            ),\n",
        "            batch_size=16,\n",
        "            epochs=10,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        X_test_dist2mip = X_test[\"X_test_dist2mip\"]\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        loss, accuracy = self.model.evaluate(\n",
        "            x=[X_test_dist2mip, X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "            y=y_test,\n",
        "            verbose=0\n",
        "        )\n",
        "        print(f\"Test Loss: {loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "        plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, filename):\n",
        "        self.load_data(filename)\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        X_train_dist2mip = np.array(X_train[\"X_train_dist2mip\"])\n",
        "\n",
        "\n",
        "\n",
        "        print(f\" in  def train(self, filename) : X_train_dist2mip shape : {X_train_dist2mip.shape}\")\n",
        "        #X_train_dist2mip = X_train_dist2mip.reshape(X_train_dist2mip.shape[0], X_train_dist2mip.shape[1],, 1)\n",
        "        #for dist in X_train_dist2mip:\n",
        "        #  print(f\"dist = {dist}\")\n",
        "\n",
        "        input_sequence_length = len(max(X_train_dist2mip, key=len))\n",
        "\n",
        "        self.build_model(input_sequence_length = input_sequence_length)\n",
        "\n",
        "        history = self.train_model(X_train, X_test, y_train, y_test)\n",
        "        self.evaluate_model(X_test, y_test)\n",
        "        self.plot_training_history(history)\n",
        "\n",
        "\n",
        "\n",
        "    def plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "      # 1. Predict labels on validation data\n",
        "\n",
        "      # 2. Calculate the difference between predicted and actual labels\n",
        "      losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "      # Sort the indices of the losses from highest to lowest\n",
        "      sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "      # Get the indices of the worst performing 10%\n",
        "      worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "      # Create figure and axes\n",
        "      num_plots = len(worst_10_percent_indices)\n",
        "      #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "      fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "      # Define mass categories\n",
        "      mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "      # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "      for i, index in enumerate(worst_10_percent_indices):\n",
        "          # Get the map and corresponding information\n",
        "          map_data = X_test_map[index, :, :]\n",
        "          actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "          print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "          predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "          ckov = X_test_ckov[index]\n",
        "          mip_position = X_test_mip_position[index]\n",
        "          momentum = X_test_momentum[index]\n",
        "          refractive_index = X_test_refractive_index[index]\n",
        "          \n",
        "          mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "          \n",
        "          # Check if the value is NaN (invalid Cherenkov angle)\n",
        "          if np.isnan(mass_actual):\n",
        "              mass_actual = \"Invalid\"\n",
        "\n",
        "          # Plot the map\n",
        "          axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "          # Add a red dot at the MIP position\n",
        "          axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "\n",
        "          # Set the title with the information\n",
        "          axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          #\n",
        "          axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "          #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          axes[i].axis('off')\n",
        "\n",
        "          print(\"\\n\")\n",
        "          print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      # Adjust the spacing between subplots\n",
        "      plt.tight_layout()\n",
        "\n",
        "      # Show the plot\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "# Usage example\n",
        "\n",
        "\n",
        "#these three have .012 in stddev\n",
        "# 3 percent occupancy:\n",
        "classifier = MassClassifier(percentage_to_read = 25, resolution = 4) # pass percentage of dataset to read \n",
        "classifier.train(\"ParticleInfo.h5\")\n",
        "\n",
        "\n",
        "# only 1 percent occupancy :\n",
        "#classifier2 = MassClassifier(percentage_to_read = 5, resolution = 4) # pass percentage of dataset to read \n",
        "#classifier2.train(\"ParticleInfo_1percent.h5\")\n",
        "\n",
        "\n",
        "#only .3 percent occupancy :\n",
        "#classifier2 = MassClassifier(percentage_to_read = 20, resolution = 4) # pass percentage of dataset to read \n",
        "#classifier2.train(\"ParticleInfo_03percent.h5\")\n",
        "\n",
        "\n",
        "\n",
        "# Less stddev in ckov photons : .07 std\n",
        "\n",
        "  #only .3 percent occupancy :\n",
        "#classifier2 = MassClassifier(percentage_to_read = 20, resolution = 4) # pass percentage of dataset to read \n",
        "#classifier2.train(\"ParticleInfo_03percent_std07.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjrxNzz0LMqU",
        "outputId": "03744bca-1970-4a15-8a42-c2a56bc9607d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of particles: 2450\n",
            "plot_maps failed due to error : name 'y_test' is not defined\n",
            "maps shape = (2450, 576, 640)\n",
            "mip_position_array shape = (2450, 2)\n",
            "distances_map_list shape = (2450,)\n",
            " X_dist2mip shape befoer pad = (2450,)\n",
            " X_dist2mip shape after pad = (2450, 36)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-f9bb0cd02ba0>:251: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  print(f\" X_dist2mip shape befoer pad = {np.array(X_dist2mip).shape}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " in  def train(self, filename) : X_train_dist2mip shape : (1960, 36)\n",
            "plot_maps failed due to error : name 'y_test' is not defined\n",
            "maps shape = (2450, 576, 640)\n",
            "mip_position_array shape = (2450, 2)\n",
            "distances_map_list shape = (2450,)\n",
            " X_dist2mip shape befoer pad = (2450,)\n",
            " X_dist2mip shape after pad = (2450, 36)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-f9bb0cd02ba0>:251: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  print(f\" X_dist2mip shape befoer pad = {np.array(X_dist2mip).shape}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1X_train_dist2mip_padded = pad_sequences(X_train_dist2mip, maxlen=input_sequence_length, padding='post', value=0.0)\n"
      ],
      "metadata": {
        "id": "NoauWOieMnWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training accuracy and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DxlPsrmTHFXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "\n",
        "\n",
        "y_train_pred = model.predict([X_train_map, X_train_momentum, X_train_refractive_index, X_train_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "#cm = confusion_matrix(y_train, y_train_pred_classes)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_train, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_train_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Training Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bLBU0quO4IYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_val_pred = model.predict([X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_val_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Validation Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v-ED5GaZ5265"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}