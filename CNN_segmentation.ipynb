{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCWx0nCQS6waqXr1gglWtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eflatlan/CNN_PID/blob/dev_floatmap/CNN_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py numpy\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrPLFO_92Cvr",
        "outputId": "e1b49525-3288-4ad2-ac9a-9b415e0c622b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py\n",
        "from helper_functions.py import print_points, plot_mapsm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "_clF1C9YOo3R",
        "outputId": "df5104d6-8601-4ad3-cc90-eb8654f7e4e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 22:13:58--  https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3879 (3.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   3.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-23 22:13:58 (63.1 MB/s) - ‘helper_functions.py’ saved [3879/3879]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5b4cc25f8eb4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://raw.githubusercontent.com/eflatlan/CNN_PID/dev_floatmap/helper_functions.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_mapsm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions.py'; 'helper_functions' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class Constants:\n",
        "    def __init__(self):\n",
        "        self.defaultPhotonEnergy = 6.75\n",
        "        self.CH4GapWidth = 8.0\n",
        "        self.RadiatorWidth = 1.0\n",
        "        self.QuartzWindowWidth = 0.5\n",
        "        self.EmissionLength = self.RadiatorWidth / 2.0\n",
        "\n",
        "class Masses:\n",
        "    def __init__(self):\n",
        "        self.mass_Pion = 0.1396\n",
        "        self.mass_Kaon = 0.4937\n",
        "        self.mass_Proton = 0.938\n",
        "\n",
        "\n",
        "# Create constants and masses objects outside of CkovCalculator\n",
        "constants = Constants()\n",
        "masses = Masses()\n",
        "\n",
        "class CkovCalculator:\n",
        "    #def __init__(self):\n",
        "        #self.constants = constants\n",
        "        #self.masses = masses\n",
        "    def GetFreonIndexOfRefraction(self, photonEnergy):\n",
        "        x = photonEnergy\n",
        "        k = 1.177 + (0.0172) * x\n",
        "        return k\n",
        "\n",
        "    def GetQuartzIndexOfRefraction(self, x):\n",
        "        k = math.sqrt(1 + 46.411 / (113.763556 - x) + 228.71 / (328.51563 - x))\n",
        "        return k\n",
        "\n",
        "    def getRadiusFromCkov(self, ckovAngle):\n",
        "        refIndexFreon = self.GetFreonIndexOfRefraction(constants.defaultPhotonEnergy)\n",
        "        refIndexQuartz = self.GetQuartzIndexOfRefraction(constants.defaultPhotonEnergy)\n",
        "        refIndexCH4 = 1.0\n",
        "\n",
        "        sin_ckov = math.sin(ckovAngle)\n",
        "        sin_qz = sin_ckov * (refIndexFreon / refIndexQuartz)\n",
        "        sin_theta0 = sin_qz * (refIndexQuartz / refIndexCH4)\n",
        "\n",
        "        R_ckov = sin_ckov * (constants.RadiatorWidth - constants.EmissionLength)\n",
        "        R_qz = sin_qz * constants.QuartzWindowWidth\n",
        "        R_0 = sin_theta0 * constants.CH4GapWidth\n",
        "\n",
        "        R = R_ckov + R_qz + R_0\n",
        "        return R\n",
        "\n",
        "    def calcCkovFromMass(self, p, n):\n",
        "        p_sq = p * p\n",
        "        cos_ckov_denom = p * n\n",
        "\n",
        "        radiuses = {}\n",
        "\n",
        "        for particle, mass in masses.__dict__.items():\n",
        "            # Skip non-mass attributes\n",
        "            if not particle.startswith(\"mass\"):\n",
        "                continue\n",
        "\n",
        "            mass_value = getattr(masses, particle)\n",
        "\n",
        "            # sanity check\n",
        "            if p_sq + mass_value * mass_value < 0:\n",
        "                radiuses[particle] = 0.0\n",
        "                continue\n",
        "\n",
        "            cos_ckov = math.sqrt(p_sq + mass_value * mass_value) / cos_ckov_denom\n",
        "\n",
        "            # sanity check\n",
        "            if cos_ckov > 1 or cos_ckov < -1:\n",
        "                radiuses[particle] = 0.0\n",
        "                continue\n",
        "\n",
        "            ckovAngle = math.acos(cos_ckov)\n",
        "            radius = self.getRadiusFromCkov(ckovAngle)\n",
        "            radiuses[particle] = radius\n",
        "            #print(f\"{particle} mass_value = {mass_value} Radius: {radius} ckov = {ckovAngle} momentum = {p} refindex = {n}\")\n",
        "\n",
        "        return radiuses\n",
        "\n",
        "\n",
        "# Usage within a loop\n",
        "for i in range(10):\n",
        "    calculator = CkovCalculator()\n",
        "    momentum = 1.5\n",
        "    refractive_index = 1.289\n",
        "    results = calculator.calcCkovFromMass(momentum, refractive_index)\n",
        "    \n",
        "    radiuses = results\n",
        "\n",
        "    radiuses = []\n",
        "\n",
        "    for particle, radius in results.items():\n",
        "        #print(f\"{particle} Radius: {radius}\")\n",
        "        radiuses.append(radius)\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "axtgHsp2colX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "\n",
        "# to check the impact of resolution in the 2d-map; \n",
        "# print the difference between the filledBins vector versus the map (map is restricted by resolution)\n",
        "def print_points(filled_bins_array = None, map_array = None, mip_position_array = None, resolution = 10):\n",
        "\n",
        "    length = map_array.shape[0]\n",
        "    distances_bins_list = []\n",
        "    distances_map_list = []\n",
        "\n",
        "    print(f\"filled_bins_array shape = {filled_bins_array.shape}\")\n",
        "    print(f\"map_array shape = {map_array.shape}\")\n",
        "    print(f\"mip_position_array shape = {mip_position_array.shape}\")\n",
        "\n",
        "\n",
        "    for i in range (1, length):\n",
        "\n",
        "        filled_bins = np.array(filled_bins_array[i])\n",
        "        map = np.array(map_array[i, :,:])\n",
        "        mip_pos = np.array(mip_position_array[i, :])\n",
        "\n",
        "        #print(f\"filled_bins shape = {filled_bins.shape}\")\n",
        "        #print(f\"map shape = {map.shape}\")\n",
        "        #print(f\"mip_pos shape = {mip_pos.shape}\")\n",
        "\n",
        "        _mip_position = []\n",
        "        #_mip_position.append(mip_position_array[])\n",
        "        distances2 = []\n",
        "\n",
        "        distances_bins = [norm(np.array(pos) - mip_pos) for pos in filled_bins]\n",
        "\n",
        "        distances_map = []\n",
        "        for y in range(map.shape[0]):\n",
        "            for x in range(map.shape[1]):\n",
        "                if map[y, x] == 1:\n",
        "                    point = (x, y)\n",
        "                    distance = np.linalg.norm(np.array(point) - mip_pos*resolution)\n",
        "                    distances_map.append(distance)\n",
        "        \n",
        "        \n",
        "        \n",
        "        distances_bins_list.append(distances_bins)\n",
        "        distances_map_list.append(distances_map)\n",
        "\n",
        "\n",
        "    # Print the distances for each element in map_data_list\n",
        "    print(f\"Element {i+1} distances:\")\n",
        "    for j, (distances_bins, distances_map) in enumerate(zip(distances_bins_list, distances_map_list)):\n",
        "        print(f\"  Point {j+1}: Distance bins: {distances_bins}\\n, Distance map: {distances_map}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_maps(filled_bins_array=None, map_array=None, mip_position_array=None, X_momentum=None, X_refractive_index=None, X_ckov=None, percentage_to_plot=5, resolution = 10):\n",
        "  \"\"\"\n",
        "  Args : filled_bins_array : array that holds the vectors of filled pads \n",
        "         map_array : 2d  map with a determined resolution (the points in the filled_bins_array element, just restricted by the resolution)\n",
        "         mip_position_array : array of the MIP {x, y} positions\n",
        "\n",
        "         TODO : add mass_category and actual mass?\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  #percentage_to_plot = 0.05 / 10\n",
        "\n",
        "  # Calculate the starting index of the samples to plot\n",
        "  num_samples = map_array.shape[0]\n",
        "  start_index = -num_samples\n",
        "\n",
        "  # Create a subplot with the number of rows based on the number of samples\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the samples and plot each map with information\n",
        "  for i, ax in enumerate(axes):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = map_array[start_index + i, :, :]\n",
        "      #mass_category = particle_vector[start_index + i].mass_category\n",
        "      ckov = X_ckov[start_index + i]\n",
        "      mip_position = mip_position_array[start_index + i]\n",
        "      momentum = X_momentum[start_index + i]\n",
        "      refractive_index = X_refractive_index[start_index + i]\n",
        "\n",
        "      # Plot the map\n",
        "      ax.imshow(map_data, cmap='gray')\n",
        "\n",
        "      # Add a red dot at the MIP position\n",
        "      ax.plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "\n",
        "      # Set the title with the information\n",
        "      #ax.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "      ax.set_title(f\"CKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum},  refractive_index: {refractive_index}\")\n",
        "\n",
        "      ax.axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y9ZOOuC_Dhay"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_random_element(X_train_map):\n",
        "    index = random.randint(0, len(X_train_map) - 1)  # Pick a random index\n",
        "    element = X_train_map[index, :, :, 0]  # Retrieve the element\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(element, cmap='viridis', origin='lower')\n",
        "    plt.title(f\"Random Element from X_train_map (Index {index})\")\n",
        "    plt.colorbar(label='Intensity')\n",
        "    plt.xlabel('X Axis')\n",
        "    plt.ylabel('Y Axis')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "FmXOGRP_UQZM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot5(X_test_map, particle_vector):\n",
        "\n",
        "  # Plotting random maps with information\n",
        "\n",
        "  # Select 5 random indices from the test data\n",
        "  random_indices = np.random.choice(range(X_test_map.shape[0]), size=5, replace=False)\n",
        "\n",
        "  # Create a subplot with 5 rows and 1 column\n",
        "  fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 20))\n",
        "\n",
        "  # Iterate over the random indices and plot each map with information\n",
        "  for i, index in enumerate(random_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :, 0]\n",
        "      mass_category = particle_vector[index].mass_category\n",
        "      ckov = particle_vector[index].ckov\n",
        "      mip_position = particle_vector[index].mip_position\n",
        "      momentum = particle_vector[index].momentum\n",
        "      \n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "      \n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "      \n",
        "      # Set the title with the information    a\n",
        "      #x.set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_position:.4f}, Momentum: {momentum:.4f}\")\n",
        "      mip_pos = f\"{mip_position:.4f}\"\n",
        "      axes[i].set_title(f\"Mass: {mass_category}, CKOV: {ckov}, MIP Position: {mip_pos}, Momentum: {momentum}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PlFS0yz2Feuz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lr_scheduler(num_epochs = 10):\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "  div = num_epochs/4\n",
        "  print(\"div =\", div)\n",
        "  print(\"1e-4 * 10**(epoch/div) = \", 1e-4 * 10**(num_epochs/div))\n",
        "  lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/div)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "  return lr_scheduler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_lr(num_epochs = 10, history = None):\n",
        "  div = num_epochs/4\n",
        "  lrs = 1e-4 * (10 ** (np.arange(num_epochs)/div))\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "  plt.xlabel(\"Learning Rate\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "\n",
        "  plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "pcY6LVGpxZQI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def plot_worst_(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "def plot_worst_(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, resolution):\n",
        "  y_pred = model.predict([X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position])\n",
        "  print(\"Shape of y_pred: \", y_pred.shape)\n",
        "  # 1. Predict labels on validation data\n",
        "#plot_worst(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "\n",
        "  # 2. Calculate the difference between predicted and actual labels\n",
        "  losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "  # Sort the indices of the losses from highest to lowest\n",
        "  sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "  # Get the indices of the worst performing 10%\n",
        "  worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "  # Create figure and axes\n",
        "  num_plots = len(worst_10_percent_indices)\n",
        "  #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "  fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "  # Define mass categories\n",
        "  mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "  # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "  for i, index in enumerate(worst_10_percent_indices):\n",
        "      # Get the map and corresponding information\n",
        "      map_data = X_test_map[index, :, :]\n",
        "      actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "      print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "      predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "      ckov = X_test_ckov[index]\n",
        "      mip_position = X_test_mip_position[index]\n",
        "      momentum = X_test_momentum[index]\n",
        "      refractive_index = X_test_refractive_index[index]\n",
        "      \n",
        "      mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "      \n",
        "      # Check if the value is NaN (invalid Cherenkov angle)\n",
        "      if np.isnan(mass_actual):\n",
        "          mass_actual = \"Invalid\"\n",
        "\n",
        "      # Plot the map\n",
        "      axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "      # Add a red dot at the MIP position\n",
        "      axes[i].plot(mip_position[0]*resolution, mip_position[1]*resolution, 'ro')\n",
        "\n",
        "      # Set the title with the information\n",
        "      axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      #\n",
        "      axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "      #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "  # Adjust the spacing between subplots\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "VRoviFHFMvUa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_window_around_mip_float(X_mip_position, X_window_sizes, X_map):\n",
        "    num_samples, height, width = X_map.shape\n",
        "    windows = []\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        center_x, center_y = X_mip_position[i]\n",
        "        window_size = X_window_sizes[i]\n",
        "        \n",
        "        # Calculate the start and end indices for the window\n",
        "        x_start = max(center_x - window_size // 2, 0)\n",
        "        x_end = min(center_x + window_size // 2, width - 1)\n",
        "        \n",
        "        y_start = max(center_y - window_size // 2, 0)\n",
        "        y_end = min(center_y + window_size // 2, height - 1)\n",
        "        \n",
        "        # Extract the window from the map\n",
        "        window = X_map[i, y_start:y_end, x_start:x_end]\n",
        "        \n",
        "        windows.append(window)\n",
        "    \n",
        "    return np.array(windows)\n",
        "\n",
        "def extract_window_around_mip(X_mip_position, X_window_sizes, X_map):\n",
        "    num_samples, height, width = X_map.shape\n",
        "    max_window_size = np.max(X_window_sizes)\n",
        "\n",
        "    # Pre-allocate the windows array with zeros\n",
        "    windows = np.zeros((num_samples, max_window_size, max_window_size))\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        center_x, center_y = map(int, X_mip_position[i]) # Ensure the positions are integers\n",
        "        window_size = X_window_sizes[i]\n",
        "        \n",
        "        # Calculate the start and end indices for the window\n",
        "        x_start = max(center_x - window_size // 2, 0)\n",
        "        x_end = min(center_x + window_size // 2 + window_size % 2, width) # + window_size % 2 to handle odd window sizes\n",
        "        \n",
        "        y_start = max(center_y - window_size // 2, 0)\n",
        "        y_end = min(center_y + window_size // 2 + window_size % 2, height) # + window_size % 2 to handle odd window sizes\n",
        "        \n",
        "        # Calculate the window's start position within the padded window\n",
        "        pad_x_start = max_window_size // 2 - (center_x - x_start)\n",
        "        pad_y_start = max_window_size // 2 - (center_y - y_start)\n",
        "        \n",
        "\n",
        "        #print(f\"pad_x_start = {pad_x_start} pad_y_start = {pad_y_start}\")\n",
        "        #print(f\"y_end = {y_end} y_start = {y_start}\")\n",
        "        #print(f\"x_end = {x_end} x_start = {x_start}\")\n",
        "\n",
        "        # Extract the window from the map and insert it into the padded window\n",
        "        windows[i, pad_y_start:pad_y_start+(y_end-y_start), pad_x_start:pad_x_start+(x_end-x_start)] = X_map[i, y_start:y_end, x_start:x_end]\n",
        "    \n",
        "    return windows\n"
      ],
      "metadata": {
        "id": "OReWmp0Mq9JY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resolution = 4\n",
        "\n",
        "print_vals = False\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Activation, Input, Conv2D, Flatten, Dense, concatenate, BatchNormalization, MaxPooling2D, Dropout, LeakyReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "class Constants:\n",
        "    PION_MASS = 0.1396\n",
        "    KAON_MASS = 0.4937\n",
        "    PROTON_MASS = 0.938\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "@staticmethod\n",
        "def calculate_mass(momentum, refractiveIndex, ckov):\n",
        "    \"\"\" args : momentum, refractiveIndex, ckov\n",
        "        returns : mass\n",
        "    \"\"\"\n",
        "    mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "    return mass\n",
        "\n",
        "\n",
        "class ParticleDataUtils:\n",
        "  \n",
        "    class ParticleInfo:\n",
        "        def __init__(self, momentum, mass, refractiveIndex, ckov, filledBins, mip_position, window_size):\n",
        "\n",
        "            self.momentum = momentum\n",
        "            self.mass = mass\n",
        "            self.refractiveIndex = refractiveIndex\n",
        "            self.ckov = ckov\n",
        "            self.filledBins = filledBins\n",
        "            self.mip_position = mip_position\n",
        "            self.mass_category = self.infer_mass_category_from_ckov(momentum, refractiveIndex, ckov)  # Infer mass category based on mass\n",
        "            self.distances_to_mip = self.calculate_distances_to_mip()  # Calculate distances\n",
        "            self.window_size = window_size\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category_from_ckov(momentum, refractiveIndex, ckov):\n",
        "            mass = momentum * np.sqrt((refractiveIndex * np.cos(ckov))**2 - 1)\n",
        "            \n",
        "            mass_category = \"unknown\"\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-4:\n",
        "                mass_category = \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-4:\n",
        "                mass_category = \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-4:\n",
        "                mass_category = \"proton\"\n",
        "            if print_vals:\n",
        "              print(f\"\\ninfer_mass_category_from_ckov :  momentum = {momentum}|  mass_calc = {mass} |  mass_category={mass_category} | refractiveIndex = {refractiveIndex} | ckov = {ckov}\")\n",
        "            return mass_category\n",
        "\n",
        "        @staticmethod\n",
        "        def infer_mass_category(mass):\n",
        "            if abs(mass - Constants.PION_MASS) < 1e-6:\n",
        "                return \"pion\"\n",
        "            elif abs(mass - Constants.KAON_MASS) < 1e-6:\n",
        "                return \"kaon\"\n",
        "            elif abs(mass - Constants.PROTON_MASS) < 1e-6:\n",
        "                return \"proton\"\n",
        "            else:\n",
        "                return \"unknown\"\n",
        "\n",
        "        def __str__(self):\n",
        "            if print_vals:\n",
        "              return (f\"ParticleInfo(momentum={self.momentum} | mass={self.mass} |  mass_category={self.mass_category} | \"\n",
        "                      f\"refractiveIndex={self.refractiveIndex} | ckov={self.ckov} | num_filled_bins={len(self.filledBins)}, \"\n",
        "                      f\"mip_position={self.mip_position})\")\n",
        "\n",
        "        def calculate_distances_to_mip(self):\n",
        "            \"\"\"Calculate Euclidean distances from all filled bins to MIP position\"\"\"\n",
        "            distances = [norm(np.array(pos) - self.mip_position) for pos in self.filledBins]\n",
        "            return distances\n",
        "\n",
        "\n",
        "    def __init__(self, filename = \"default_filename.h5\", percentage_to_read = 100):\n",
        "        self.filename = filename\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.particle_vector = self.load_data(filename)\n",
        "        self.particle_info = self.process_data(self.particle_vector, self.percentage_to_read)\n",
        "        self.num_particles = len(self.particle_info)\n",
        "        self.momentum_scaler, self.momentum_stats = self.create_scaler(\"momentum\")\n",
        "        self.refractive_index_scaler, self.refractive_index_stats = self.create_scaler(\"refractiveIndex\")\n",
        "        self.ckov_scaler, self.ckov_stats = self.create_scaler(\"ckov\")\n",
        "        self.distances_scaler, self.distances_stats = self.create_scaler(\"distances\")\n",
        "\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        drive_path = '/content/drive/MyDrive/Colab Notebooks/CERN_ML/CNN_PID/'  # Update the path to your Google Drive folder\n",
        "        file_path = os.path.join(drive_path, filename)\n",
        "        particle_vector = []\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            #file.visititems(print_hdf5_items)\n",
        "            for i, group_name in enumerate(file):\n",
        "                group = file[group_name]\n",
        "\n",
        "                # Read scalar values\n",
        "                momentum = group.attrs['Momentum']\n",
        "                mass = group.attrs['Mass']\n",
        "                refractiveIndex = group.attrs['RefractiveIndex']\n",
        "                ckov = group.attrs['Ckov']\n",
        "                mip_position = group['MipPos']\n",
        "                mip_position = mip_position[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                mip_position = mip_position.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                # Read filledBins\n",
        "                filled_bins_dataset = group['FilledBins']\n",
        "                filled_bins_data = filled_bins_dataset[...]  # Retrieve the data as a numpy array\n",
        "\n",
        "                filled_bins = filled_bins_data.tolist()  # Convert the numpy array to a list\n",
        "\n",
        "                # get window : \n",
        "                calculator = CkovCalculator()\n",
        "                results = calculator.calcCkovFromMass(momentum, refractive_index)\n",
        "                radiuses = []\n",
        "                for particle, radius in results.items():\n",
        "                    #print(f\"{particle} Radius: {radius}\")\n",
        "                    radiuses.append(radius)\n",
        "\n",
        "                # the biggest radius should then extract a window around the MIP \n",
        "\n",
        "                # Find the particle with the biggest radius\n",
        "                #max_radius_particle = max(radiuses, key=radiuses.get)\n",
        "                #max_radius = radiuses[max_radius_particle]\n",
        "                max_radius = radiuses[2]\n",
        "\n",
        "                # Extract a window around the MIP using the biggest radius\n",
        "                window_size = int(max_radius * 2)  # Adjust the size as needed      \n",
        "                # NB!!! add resolution here? Or multiply elswhere..\n",
        "\n",
        "                particle_info = ParticleDataUtils.ParticleInfo(\n",
        "                    momentum, mass, refractiveIndex, ckov, filledBins=filled_bins, mip_position=mip_position, window_size = window_size)\n",
        "                if print_vals == True:\n",
        "                  print(particle_info)  # This will use the __str__() method of ParticleInfo\n",
        "\n",
        "                particle_vector.append(particle_info)\n",
        "\n",
        "        return particle_vector\n",
        "\n",
        "    def process_data(self, particle_vector, percentage):\n",
        "\n",
        "        # Calculate the number of particles based on the percentage\n",
        "        num_particles = int(len(particle_vector) * (percentage / 100.0))\n",
        "\n",
        "        # Slice the particle_vector to the desired percentage\n",
        "        particle_vector = particle_vector[:num_particles]\n",
        "        return particle_vector\n",
        "\n",
        "\n",
        "    def create_scaler(self, feature):\n",
        "        if feature == \"momentum\":\n",
        "            values = np.array([info.momentum for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"refractiveIndex\":\n",
        "            values = np.array([info.refractiveIndex for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"ckov\":\n",
        "            values = np.array([info.ckov for info in self.particle_info]).reshape(-1, 1)\n",
        "        elif feature == \"distances\":\n",
        "            distances = []\n",
        "            for info in self.particle_info:\n",
        "                distances.extend(info.distances_to_mip)\n",
        "            values = np.array(distances).reshape(-1, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid feature: {feature}\")\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaled_values = scaler.fit_transform(values)\n",
        "        stats = {\n",
        "            \"mean\": scaler.mean_[0],\n",
        "            \"std\": scaler.scale_[0]\n",
        "        }\n",
        "        return scaler, stats\n",
        "\n",
        "\n",
        "\n",
        "# create a map, the resolution is the \"inverse\" \n",
        "def create_map(filledBins=None, resolution=4):\n",
        "    map_shape = (int(144 * resolution), int(160 * resolution))\n",
        "    map_data = np.zeros(map_shape)\n",
        "    \n",
        "    if filledBins is not None:\n",
        "        for bins in filledBins:\n",
        "            x, y = bins\n",
        "            x_index = int(x * resolution)\n",
        "            y_index = int(y * resolution)\n",
        "            map_data[y_index, x_index] = 1\n",
        "\n",
        "    return map_data\n",
        "\n",
        "class MassClassifier:\n",
        "    def __init__(self, percentage_to_read = 10, resolution = 4):\n",
        "        self.model = None\n",
        "        self.utils = None\n",
        "        self.percentage_to_read = percentage_to_read\n",
        "        self.resolution = resolution\n",
        "\n",
        "\n",
        "    def load_data(self, filename):\n",
        "        self.utils = ParticleDataUtils(filename, percentage_to_read = self.percentage_to_read) # specify percentage of particles to read..\n",
        "        print(f\"Number of particles: {self.utils.num_particles}\")\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        particle_info = self.utils.particle_info\n",
        "\n",
        "\n",
        "        # Prepare the inputs\n",
        "        \n",
        "        # create a map with resolution to be chosen, iterate over teh filledBins vector\n",
        "        X_map = np.array([create_map(filledBins = info.filledBins, resolution = self.resolution) for info in particle_info])\n",
        "        filled_bins_array = np.array([info.filledBins for info in particle_info], dtype=object)\n",
        "\n",
        "        filled_bins_array = np.array([info.filledBins for info in particle_info], dtype=object)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        X_momentum = np.array([info.momentum for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_refractive_index = np.array([info.refractiveIndex for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_ckov = np.array([info.ckov for info in particle_info])#.reshape(-1, 32, 32, 1)\n",
        "        X_mip_position = np.array([info.mip_position for info in particle_info])\n",
        "\n",
        "        # window-sizes\n",
        "        X_window_sizes = np.array([info.window_size for info in particle_info])\n",
        "        # extracting the window around the MIP:\n",
        "        X_windows = extract_window_around_mip(X_mip_position, X_window_sizes, X_map)\n",
        "        # X_windows will have various size (X_window_sizes + pad) x (X_window_sizes + pad) \n",
        "\n",
        "\n",
        "        # check the impact of resolution:\n",
        "        #print_points(filled_bins_array = filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, resolution = resolution)\n",
        "\n",
        "        # plot the points and the MIP\n",
        "        #plot_maps(filled_bins_array =filled_bins_array, map_array = X_map, mip_position_array= X_mip_position, X_momentum = X_momentum, X_refractive_index= X_refractive_index, X_ckov = X_ckov, percentage_to_plot=5, resolution = resolution)\n",
        "\n",
        "\n",
        "        # Normalize the inputs NB commented out scaling !!!\n",
        "        #X_momentum = self.utils.momentum_scaler.transform(X_momentum.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_refractive_index = self.utils.refractive_index_scaler.transform(X_refractive_index.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "        #X_ckov = self.utils.ckov_scaler.transform(X_ckov.reshape(-1, 1))#.reshape(-1, 32, 32, 1)\n",
        "\n",
        "        #X_mip_position[0,:] = self.utils.distances_scaler.transform(X_mip_position[0,:])\n",
        "        #X_mip_position[1,:] = self.utils.distances_scaler.transform(X_mip_position[1,:])\n",
        "\n",
        "\n",
        "\n",
        "        # Prepare the outputs\n",
        "        y = np.array([info.mass_category for info in particle_info])\n",
        "\n",
        "        # Convert the outputs to one-hot encoded vectors\n",
        "        lb = LabelBinarizer()\n",
        "        y = lb.fit_transform(y)\n",
        "\n",
        "        # Split the data into train and test sets\n",
        "\n",
        "        X_train_windows, X_test_windows, X_train_map, X_test_map, X_train_momentum, X_test_momentum, X_train_refractive_index, X_test_refractive_index, \\\n",
        "            X_train_ckov, X_test_ckov, X_train_mip_position, X_test_mip_position, y_train, y_test = \\\n",
        "            train_test_split(X_windows, X_map, X_momentum, X_refractive_index, X_ckov, X_mip_position, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        X_train = {\"X_train_map\": X_train_map, \"X_train_momentum\": X_train_momentum, \"X_train_refractive_index\": X_train_refractive_index, \"X_train_ckov\": X_train_ckov, \"X_train_mip_position\": X_train_mip_position, \"X_train_windows\": X_train_windows}\n",
        "        X_test = {\"X_test_map\": X_test_map, \"X_test_momentum\": X_test_momentum, \"X_test_refractive_index\": X_test_refractive_index, \"X_test_ckov\": X_test_ckov, \"X_test_mip_position\": X_test_mip_position, \"X_test_windows\": X_test_windows}\n",
        "\n",
        "        return (X_train, X_test, y_train, y_test)\n",
        "\n",
        "    def build_model(self, map_shape=(None, 2, 1)):\n",
        "\n",
        "        map_shape = (None, None, 1)  # Variable shape for the map input\n",
        "\n",
        "        momentum_shape = (1,)\n",
        "        refractive_index_shape = (1,)\n",
        "        mip_position_shape = (2,)\n",
        "\n",
        "        # Grid search parameters\n",
        "        # Grid search parameters\n",
        "        filter_sizes = [5]  # Filter sizes to test\n",
        "        num_filters = [32]#[16, 32]  # Number of filters to test\n",
        "        strides = [(2, 2)]#[(1, 1), (2, 2)]  # Strides to test\n",
        "        pool_sizes = [(2, 2)]  # Max pooling sizes to test\n",
        "        fc1_units = [64]#, 128]  # Number of units in fc1 to test\n",
        "        fc2_units = [16]#, 32]  # Number of units in fc2 to test\n",
        "\n",
        "        best_accuracy = 0\n",
        "        best_model = None\n",
        "\n",
        "        for filter_size in filter_sizes:\n",
        "            for num_filter in num_filters:\n",
        "                for stride in strides:\n",
        "                    for pool_size in pool_sizes:\n",
        "                        for fc1_unit in fc1_units:\n",
        "                            for fc2_unit in fc2_units:\n",
        "                              # Create a new model configuration\n",
        "                              map_input = Input(shape=map_shape, name=\"map_input\")\n",
        "                              momentum_input = Input(shape=momentum_shape, name=\"momentum_input\")\n",
        "                              refractive_index_input = Input(shape=refractive_index_shape, name=\"refractive_index_input\")\n",
        "                              mip_position_input = Input(shape=mip_position_shape, name=\"mip_position_input\")\n",
        "\n",
        "                              # Window Input\n",
        "                              window_shape=(None, None, 1)\n",
        "                              window_input = Input(shape=window_shape, name=\"window_input\")\n",
        "                              conv1 = Conv2D(64, (3, 3), padding='same')(window_input)\n",
        "                              conv1 = Activation('relu')(conv1)\n",
        "                              conv2 = Conv2D(128, (3, 3), padding='same')(conv1)\n",
        "                              conv2 = Activation('relu')(conv2)\n",
        "                              flat_window = Flatten()(conv2)\n",
        "\n",
        "                              # Refractive index Input\n",
        "                              refractive_index_input = Input(shape=refractive_index_shape, name=\"refractive_index_input\")\n",
        "                              dense1 = Dense(32, activation='relu')(refractive_index_input)\n",
        "\n",
        "                              # Momentum Input\n",
        "                              momentum_input = Input(shape=momentum_shape, name=\"momentum_input\")\n",
        "                              dense2 = Dense(32, activation='relu')(momentum_input)\n",
        "\n",
        "                              # MIP Position Input\n",
        "                              mip_position_input = Input(shape=mip_position_shape, name=\"mip_position_input\")\n",
        "                              dense3 = Dense(32, activation='relu')(mip_position_input)\n",
        "\n",
        "                              # Concatenation\n",
        "                              concat = concatenate([flat_window, dense1, dense2, dense3])\n",
        "\n",
        "                              output = Dense(3, activation='softmax')(conv2) # NB LEGG MERKE TIL AT DENNE ER ENDRET FRA FC2\n",
        "\n",
        "                              model = Model(inputs=[map_input, momentum_input, refractive_index_input, mip_position_input],\n",
        "                                            outputs=output)\n",
        "\n",
        "                              model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), # NB changed from 0.0002\n",
        "                                            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "                              X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "\n",
        "                              # Train the model\n",
        "                              history = model.fit(\n",
        "                                  x=[X_train[\"X_train_windows\"], X_train[\"X_train_momentum\"], X_train[\"X_train_refractive_index\"],\n",
        "                                    X_train[\"X_train_mip_position\"]],\n",
        "                                  y=y_train,\n",
        "                                  validation_data=(\n",
        "                                      [X_test[\"X_test_windows\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                      X_test[\"X_test_mip_position\"]],\n",
        "                                      y_test\n",
        "                                  ),\n",
        "                                  batch_size=32,\n",
        "                                  epochs=20,\n",
        "                                  verbose=1\n",
        "                              )\n",
        "\n",
        "                              # plotting the worst cases?:\n",
        "                              #y_pred_test = model.predict([X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_mip_position\"]])\n",
        "                              #plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "                              print(\"Shape of y_test: \", y_test.shape)\n",
        "                              print(\"Shape of X_test_map: \", X_test[\"X_test_map\"].shape)\n",
        "                              print(\"Shape of X_test_windows: \", X_test[\"X_test_windows\"].shape)\n",
        "                              print(\"Shape of X_test_momentum: \", X_test[\"X_test_momentum\"].shape)\n",
        "                              print(\"Shape of X_test_refractive_index: \", X_test[\"X_test_refractive_index\"].shape)\n",
        "                              print(\"Shape of X_test_ckov: \", X_test[\"X_test_ckov\"].shape)\n",
        "                              print(\"Shape of X_test_mip_position: \", X_test[\"X_test_mip_position\"].shape)\n",
        "                              #print(\"Shape of y_pred_test: \", y_pred_test.shape)\n",
        "                              try: # NB! commented out this line\n",
        "                                #plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], y_pred_test)\n",
        "                                plot_worst_(model, y_test, X_test[\"X_test_map\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"], X_test[\"X_test_ckov\"], X_test[\"X_test_mip_position\"], self.resolution)\n",
        "                              except Exception as e:\n",
        "                                print(f\"skip plot_worst_ due to error: {e}\")\n",
        "                              self.plot_training_history(history)\n",
        "\n",
        "                              # Evaluate the model\n",
        "                              _, accuracy = model.evaluate(\n",
        "                                  x=[X_test[\"X_test_windows\"], X_test[\"X_test_momentum\"], X_test[\"X_test_refractive_index\"],\n",
        "                                    X_test[\"X_test_mip_position\"]],\n",
        "                                  y=y_test,\n",
        "                                  verbose=1\n",
        "                              )\n",
        "\n",
        "                              print(f\"Model Accuracy: {accuracy:.4f} (Filter Size: {filter_size}, Num Filters: {num_filter}, \"\n",
        "                                    f\"Stride: {stride}, Pool Size: {pool_size})\")\n",
        "\n",
        "                              # Check if the current model configuration is better\n",
        "                              if accuracy > best_accuracy:\n",
        "                                  best_accuracy = accuracy\n",
        "                                  best_model = model\n",
        "\n",
        "        # Set the best model as the final model\n",
        "        self.model = best_model\n",
        "\n",
        "\n",
        "    def train_model(self, X_train, X_test, y_train, y_test):\n",
        "        # Compile the model\n",
        "\n",
        "\n",
        "        X_train_map = X_train[\"X_train_map\"]\n",
        "        X_train_windows = X_train[\"X_train_windows\"]\n",
        "        X_train_momentum = X_train[\"X_train_momentum\"]\n",
        "        X_train_refractive_index = X_train[\"X_train_refractive_index\"]\n",
        "        X_train_ckov = X_train[\"X_train_ckov\"]\n",
        "        X_train_mip_position = X_train[\"X_train_mip_position\"]\n",
        "\n",
        "        X_test_map = X_test[\"X_test_map\"]\n",
        "        X_test_windows = X_train[\"X_test_windows\"]\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        # Print fields in the first vector of X_train\n",
        "        print(\"Fields in the first vector of X_train:\")\n",
        "        print(\"X_train_map shape:\", X_train_map.shape)\n",
        "        print(\"X_train_momentum shape:\", X_train_momentum.shape)\n",
        "        print(\"X_train_refractive_index shape:\", X_train_refractive_index.shape)\n",
        "        print(\"X_train_ckov shape:\", X_train_ckov.shape)\n",
        "        print(\"X_train_mip_position shape:\", X_train_mip_position.shape)\n",
        "\n",
        "        # Print the first element of y_train\n",
        "        print(\"First element of y_train:\", y_train[0])\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            x=[X_train_windows, X_train_momentum, X_train_refractive_index, X_train_mip_position], # [X_train_map, X_train_momentum, X_train_refractive_index, X_train_ckov, X_train_mip_position]\n",
        "            y=y_train,\n",
        "            validation_data=(\n",
        "                [X_test_windows, X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "                y_test\n",
        "            ),\n",
        "            batch_size=16,\n",
        "            epochs=10,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        X_test_windows = X_test[\"X_test_windows\"]\n",
        "        X_test_momentum = X_test[\"X_test_momentum\"]\n",
        "        X_test_refractive_index = X_test[\"X_test_refractive_index\"]\n",
        "        X_test_ckov = X_test[\"X_test_ckov\"]\n",
        "        X_test_mip_position = X_test[\"X_test_mip_position\"]\n",
        "        loss, accuracy = self.model.evaluate(\n",
        "            x=[X_test_windows, X_test_momentum, X_test_refractive_index, X_test_mip_position],\n",
        "            y=y_test,\n",
        "            verbose=0\n",
        "        )\n",
        "        print(f\"Test Loss: {loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "        plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, filename):\n",
        "        self.load_data(filename)\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        X_train_map = X_train[\"X_train_map\"]\n",
        "        X_train_map = X_train_map.reshape(X_train_map.shape[0], X_train_map.shape[1], X_train_map.shape[2], 1)\n",
        "        self.build_model(map_shape = X_train_map.shape[1:])\n",
        "        history = self.train_model(X_train, X_test, y_train, y_test)\n",
        "        self.evaluate_model(X_test, y_test)\n",
        "        self.plot_training_history(history)\n",
        "\n",
        "\n",
        "\n",
        "    def plot_worst(model, y_test, X_test_map, X_test_momentum, X_test_refractive_index, X_test_ckov, X_test_mip_position, y_pred):\n",
        "      # 1. Predict labels on validation data\n",
        "\n",
        "      # 2. Calculate the difference between predicted and actual labels\n",
        "      losses = tf.keras.losses.categorical_crossentropy(y_test, y_pred).numpy()\n",
        "\n",
        "      # Sort the indices of the losses from highest to lowest\n",
        "      sorted_indices = np.argsort(losses)[::-1]\n",
        "\n",
        "      # Get the indices of the worst performing 10%\n",
        "      worst_10_percent_indices = sorted_indices[:int(0.1*len(sorted_indices))]\n",
        "\n",
        "      # Create figure and axes\n",
        "      num_plots = len(worst_10_percent_indices)\n",
        "      #fig, axes = plt.subplots(num_plots, 1, figsize=(8, 20))\n",
        "      fig, axes = plt.subplots(num_plots,figsize=(8, 20))\n",
        "\n",
        "      # Define mass categories\n",
        "      mass_categories = [\"pion\", \"kaon\", \"proton\"]\n",
        "\n",
        "      # 3. Create plots for these cases, including their feature information and predicted vs actual labels\n",
        "      for i, index in enumerate(worst_10_percent_indices):\n",
        "          # Get the map and corresponding information\n",
        "          map_data = X_test_map[index, :, :]\n",
        "          actual_mass_category = mass_categories[np.argmax(y_test[index])]\n",
        "\n",
        "          print(f\"y_test[index] = {y_test[index]}\")\n",
        "\n",
        "          predicted_mass_category = mass_categories[np.argmax(y_pred[index])]\n",
        "          ckov = X_test_ckov[index]\n",
        "          mip_position = X_test_mip_position[index]\n",
        "          momentum = X_test_momentum[index]\n",
        "          refractive_index = X_test_refractive_index[index]\n",
        "          \n",
        "          mass_actual = momentum * np.sqrt(refractive_index**2 * np.cos(ckov)*np.cos(ckov) - 1)\n",
        "          \n",
        "          # Check if the value is NaN (invalid Cherenkov angle)\n",
        "          if np.isnan(mass_actual):\n",
        "              mass_actual = \"Invalid\"\n",
        "\n",
        "          # Plot the map\n",
        "          axes[i].imshow(map_data, cmap='gray')\n",
        "\n",
        "          # Add a red dot at the MIP position\n",
        "          axes[i].plot(mip_position[0], mip_position[1], 'ro')\n",
        "\n",
        "          # Set the title with the information\n",
        "          axes[i].set_title(f\"Actual Mass\")#: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          #\n",
        "          axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\nMass: {mass_actual}, Mass_prob = {y_pred[index]} \\nCKOV: {ckov}, MIP Position: {mip_position}, \\nMomentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "\n",
        "          #axes[i].set_title(f\"Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category}, Mass: {mass_actual}\\nCKOV: {ckov}, MIP Position: {mip_position}, Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "          axes[i].axis('off')\n",
        "\n",
        "          print(\"\\n\")\n",
        "          print(f\"  Actual Mass: {actual_mass_category}, Predicted Mass: {predicted_mass_category},\\n Mass: {mass_actual}, Mass_prob = {y_pred[index]} \\n CKOV: {ckov}, MIP Position: {mip_position}, \\n  Momentum: {momentum}, Refractive Index: {refractive_index}\")\n",
        "      # Adjust the spacing between subplots\n",
        "      plt.tight_layout()\n",
        "\n",
        "      # Show the plot\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "# Usage example\n",
        "classifier = MassClassifier(percentage_to_read = 10, resolution = 4) # pass percentage of dataset to read \n",
        "classifier.train(\"ParticleInfo.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "IjrxNzz0LMqU",
        "outputId": "4e040e86-7212-42d7-ceb2-804ee3abc8c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of particles: 977\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-51a53b51d392>\u001b[0m in \u001b[0;36m<cell line: 550>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;31m# Usage example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMassClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentage_to_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pass percentage of dataset to read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ParticleInfo.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-51a53b51d392>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mX_train_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_train_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mX_train_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-51a53b51d392>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, map_shape)\u001b[0m\n\u001b[1;32m    332\u001b[0m                               \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NB LEGG MERKE TIL AT DENNE ER ENDRET FRA FC2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                               model = Model(inputs=[map_input, momentum_input, refractive_index_input, mip_position_input],\n\u001b[0m\u001b[1;32m    335\u001b[0m                                             outputs=output)\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 )\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m   1143\u001b[0m                             \u001b[0;34m\"Graph disconnected: cannot obtain value for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                             \u001b[0;34mf'tensor {x} at layer \"{layer.name}\". '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name='window_input'), name='window_input', description=\"created by layer 'window_input'\") at layer \"conv2d_6\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoauWOieMnWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training accuracy and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DxlPsrmTHFXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "\n",
        "\n",
        "y_train_pred = model.predict([X_train_map, X_train_momentum, X_train_refractive_index, X_train_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "#cm = confusion_matrix(y_train, y_train_pred_classes)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_train, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_train_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Training Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bLBU0quO4IYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_val_pred = model.predict([X_test_map, X_test_momentum, X_test_refractive_index, X_test_mip_position])\n",
        "\n",
        "# Convert the predictions from categorical back to original labels\n",
        "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(rounded_labels, y_val_pred_classes)\n",
        "\n",
        "# Use seaborn to visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix Validation Data')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v-ED5GaZ5265"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}